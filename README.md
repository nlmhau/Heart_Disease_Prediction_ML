> **Äá»“ Ã¡n mÃ´n há»c Machine Learning (Há»c MÃ¡y)**  
> **Lá»›p:** S26-65TTNT - NhÃ³m 7  
> **Sá»­ dá»¥ng Ensemble Learning vÃ  Deep Learning vá»›i PhÃ¢n tÃ­ch Máº«u áº¨n (Hidden Pattern Analysis)**

---

##  Giá»›i Thiá»‡u

Dá»± Ã¡n nÃ y xÃ¢y dá»±ng má»™t mÃ´ hÃ¬nh Machine Learning Ä‘á»ƒ dá»± Ä‘oÃ¡n kháº£ nÄƒng máº¯c bá»‡nh tim dá»±a trÃªn cÃ¡c chá»‰ sá»‘ lÃ¢m sÃ ng. Má»¥c tiÃªu lÃ  tá»‘i Æ°u hÃ³a quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u vÃ  Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c cao trÃªn táº­p kiá»ƒm thá»­.

- **Random Forest** - Ensemble Learning vá»›i cÃ¢y quyáº¿t Ä‘á»‹nh
- **XGBoost** - Gradient Boosting tá»‘i Æ°u hÃ³a
- **Neural Network** - Deep Learning vá»›i MLPClassifier

Há»‡ thá»‘ng khÃ´ng chá»‰ dá»± Ä‘oÃ¡n nguy cÆ¡ mÃ  cÃ²n **phÃ¡t hiá»‡n cÃ¡c máº«u áº©n (Hidden Patterns)** - nhá»¯ng tá»• há»£p triá»‡u chá»©ng Ä‘áº·c biá»‡t dáº«n Ä‘áº¿n bá»‡nh tim, giÃºp há»— trá»£ quyáº¿t Ä‘á»‹nh y khoa.

###  Má»¥c TiÃªu Há»c Táº­p

- Ãp dá»¥ng ká»¹ thuáº­t tiá»n xá»­ lÃ½ dá»¯ liá»‡u y táº¿ (xá»­ lÃ½ missing values, outliers)
- Thá»±c hiá»‡n Feature Engineering dá»±a trÃªn kiáº¿n thá»©c y khoa
- So sÃ¡nh hiá»‡u nÄƒng cá»§a cÃ¡c thuáº­t toÃ¡n ML khÃ¡c nhau
- Tá»‘i Æ°u hÃ³a ngÆ°á»¡ng dá»± Ä‘oÃ¡n (Threshold Tuning) cho bÃ i toÃ¡n y táº¿
- Giáº£i thÃ­ch mÃ´ hÃ¬nh (Model Interpretability) vá»›i Permutation Importance
- XÃ¢y dá»±ng Web Application Ä‘á»ƒ demo sáº£n pháº©m

---

##  Äáº·c Äiá»ƒm Ná»•i Báº­t

###  Ká»¹ Thuáº­t Cao

1. **Pipeline Tiá»n Xá»­ LÃ½**
   - Iterative Imputer (MICE) cho missing values
   - RobustScaler chá»‘ng outlier
   - Feature Engineering dá»±a y khoa (Cholesterol/Tuá»•i, Nguy cÆ¡ tim máº¡ch ráº¥t cao)

2. **Hyperparameter Tuning**
   - Grid Search CV vá»›i 5-fold cross-validation
   - Tá»‘i Æ°u hÃ³a theo Recall (Æ°u tiÃªn phÃ¡t hiá»‡n bá»‡nh nhÃ¢n)

3. **Threshold Tuning**
   - TÃ¬m ngÆ°á»¡ng cáº¯t tá»‘i Æ°u (thay vÃ¬ 0.5 máº·c Ä‘á»‹nh)
   - Tá»‘i Ä‘a hÃ³a F1-Score Ä‘á»ƒ cÃ¢n báº±ng Precision vÃ  Recall

4. **Hidden Pattern Analysis** 
   - TrÃ­ch xuáº¥t quy luáº­t tá»« Random Forest (89 patterns)
   - PhÃ¢n tÃ­ch tÆ°Æ¡ng tÃ¡c Ä‘áº·c trÆ°ng tá»« XGBoost
   - Giáº£i mÃ£ "há»™p Ä‘en" Neural Network

5. **Model Interpretability**
   - Permutation Importance
   - Feature Importance Visualization
   - Decision Tree Extraction

###  ÄÃ¡nh GiÃ¡ ToÃ n Diá»‡n

- Confusion Matrix chi tiáº¿t
- ROC Curve vÃ  AUC-ROC Score
- Classification Report Ä‘áº§y Ä‘á»§
- So sÃ¡nh 3 mÃ´ hÃ¬nh trÃªn cÃ¹ng test set

---

##  Dataset

### ThÃ´ng Tin Chung

- **TÃªn Dataset:** Heart Disease Dataset
- **Nguá»“n:** [Kaggle](https://www.kaggle.com/datasets/tan5577/heart-failure-dataset)
- **Sá»‘ Máº«u:** 918 bá»‡nh nhÃ¢n
- **Sá»‘ Äáº·c TrÆ°ng:** 11 features + 1 target
- **PhÃ¢n Bá»‘ Lá»›p:**
  - Khá»e máº¡nh (0): 410 ngÆ°á»i (44.7%)
  - Bá»‡nh tim (1): 508 ngÆ°á»i (55.3%)

### CÃ¡c Äáº·c TrÆ°ng (Features)

| TÃªn Gá»‘c | TÃªn Tiáº¿ng Viá»‡t | Loáº¡i | MÃ´ Táº£ |
|----------|----------------|------|-------|
| Age | Tuá»•i | Sá»‘ | Tuá»•i cá»§a bá»‡nh nhÃ¢n (28-77) |
| Sex | Giá»›i_tÃ­nh | PhÃ¢n loáº¡i | M (Nam), F (Ná»¯) |
| ChestPainType | Loáº¡i_Äau_Ngá»±c | PhÃ¢n loáº¡i | TA, ATA, NAP, ASY |
| RestingBP | Huyáº¿t_Ãp_Nghá»‰ | Sá»‘ | Huyáº¿t Ã¡p tÃ¢m thu (mmHg) |
| Cholesterol | Cholesterol | Sá»‘ | Cholesterol toÃ n pháº§n (mg/dL) |
| FastingBS | ÄÆ°á»ng_Huyáº¿t_ÄÃ³i | Nhá»‹ phÃ¢n | 1 náº¿u > 120 mg/dL |
| RestingECG | Äiá»‡n_TÃ¢m_Äá»“ | PhÃ¢n loáº¡i | Normal, ST, LVH |
| MaxHR | Nhá»‹p_Tim_Tá»‘i_Äa | Sá»‘ | Nhá»‹p tim tá»‘i Ä‘a (60-202) |
| ExerciseAngina | Äau_Tháº¯t_Váº­n_Äá»™ng | Nhá»‹ phÃ¢n | Y (CÃ³), N (KhÃ´ng) |
| Oldpeak | Äá»™_ChÃªnh_ST | Sá»‘ | ST depression (-2.6 Ä‘áº¿n 6.2) |
| ST_Slope | Äá»™_Dá»‘c_ST | PhÃ¢n loáº¡i | Up, Flat, Down |
| **HeartDisease** | **Bá»‡nh_Tim** | **Target** | **0 (Khá»e), 1 (Bá»‡nh)** |

### PhÃ¢n TÃ­ch Cháº¥t LÆ°á»£ng Dá»¯ Liá»‡u

- **Missing Values:**
  - Cholesterol = 0: 172 giÃ¡ trá»‹ (18.7%) â†’ Thay báº±ng NaN vÃ  impute
  - Huyáº¿t_Ãp_Nghá»‰ = 0: 1 giÃ¡ trá»‹ â†’ Thay báº±ng NaN vÃ  impute
  
- **GiÃ¡ Trá»‹ Ã‚m:**
  - Äá»™_ChÃªnh_ST < 0: 13 giÃ¡ trá»‹
  - **Quyáº¿t Ä‘á»‹nh:** GIá»® NGUYÃŠN (cÃ³ Ã½ nghÄ©a y khoa - ST Elevation trong nhá»“i mÃ¡u cÆ¡ tim cáº¥p)
  - NhÃ³m nÃ y cÃ³ tá»· lá»‡ bá»‡nh **69.23%** (cao hÆ¡n trung bÃ¬nh 55.34%)

---

##  Cáº¥u TrÃºc Dá»± Ãn

```
S26-65TTNT_Nhom7_DuDoanBenhTim/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ heart.csv                          # Dataset gá»‘c
â”‚
â”œâ”€â”€ reports/ 
â”‚  â””â”€â”€ N7_report.pdf                       # BÃ¡o cÃ¡o
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py                   # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u & Pipeline
â”‚   â”œâ”€â”€ feature_engineering.py             # Táº¡o Ä‘áº·c trÆ°ng y khoa
â”‚   â”œâ”€â”€ eda.py                             # PhÃ¢n tÃ­ch khÃ¡m phÃ¡ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ RandomForest_NguyenLeMinhHau.py    # MÃ´ hÃ¬nh Random Forest
â”‚   â”œâ”€â”€ XGBoost_NguyenLeMinhHau.py         # MÃ´ hÃ¬nh XGBoost
â”‚   â”œâ”€â”€ NeuralNetwork_NguyenDucHuy.py      # MÃ´ hÃ¬nh Neural Network
â”‚   â”œâ”€â”€ evaluation.py                      # So sÃ¡nh & Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh
â”‚   â””â”€â”€ app.py                             # Streamlit Web Application
â”‚
â”œâ”€â”€ saved_models/
â”‚   â”œâ”€â”€ random_forest.pkl                  # MÃ´ hÃ¬nh RF Ä‘Ã£ train
â”‚   â”œâ”€â”€ xgboost.pkl                        # MÃ´ hÃ¬nh XGB Ä‘Ã£ train
â”‚   â”œâ”€â”€ neural_network.pkl                 # MÃ´ hÃ¬nh NN Ä‘Ã£ train
â”‚   â”œâ”€â”€ scaler.pkl                         # RobustScaler
â”‚   â”œâ”€â”€ imputer.pkl                        # Iterative Imputer
â”‚   â”œâ”€â”€ feature_columns.pkl                # Danh sÃ¡ch features
â”‚   â”œâ”€â”€ X_train.pkl, X_test.pkl            # Dá»¯ liá»‡u train/test
â”‚   â””â”€â”€ *.metadata.pkl                     # Metadata cá»§a mÃ´ hÃ¬nh
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/                           # CÃ¡c biá»ƒu Ä‘á»“ (ROC, Confusion Matrix, etc.)
â”‚   | 
â”‚   â”œâ”€â”€ preprocessing_log.txt              # Log tiá»n xá»­ lÃ½
â”‚   â”œâ”€â”€ eda_log.txt                        # Log phÃ¢n tÃ­ch EDA
â”‚   â”œâ”€â”€ RandomForest_log.txt               # Log huáº¥n luyá»‡n RF
â”‚   â”œâ”€â”€ XGBoost_log.txt                    # Log huáº¥n luyá»‡n XGB
â”‚   â”œâ”€â”€ NeuralNetwork_log.txt              # Log huáº¥n luyá»‡n NN
â”‚   â”œâ”€â”€ Evaluation_log.txt                 # Log Ä‘Ã¡nh giÃ¡
â”‚   â””â”€â”€ Evaluation_Report.txt              # BÃ¡o cÃ¡o tá»•ng há»£p
â”‚ 
â”œâ”€â”€ generate_report.py                     # Script táº¡o bÃ¡o cÃ¡o Word
â”œâ”€â”€ requirements.txt                       # Dependencies
â”œâ”€â”€ README.md                              # File nÃ y
â””â”€â”€ .venv/                                 # Virtual environment
```

---

##  YÃªu Cáº§u Há»‡ Thá»‘ng

### Pháº§n Cá»©ng

- **RAM:** Tá»‘i thiá»ƒu 4GB (Khuyáº¿n nghá»‹ 8GB+)
- **CPU:** Multi-core (Grid Search sá»­ dá»¥ng Ä‘a luá»“ng)
- **á»” ÄÄ©a:** ~500MB cho dependencies + models

### Pháº§n Má»m

- **Python:** 3.9 - 3.11
- **Há»‡ Äiá»u HÃ nh:** Windows 10/11, macOS, Linux

### ThÆ° Viá»‡n ChÃ­nh

| ThÆ° viá»‡n | Version | Má»¥c Ä‘Ã­ch |
|----------|---------|----------|
| pandas | â‰¥2.0.0 | Xá»­ lÃ½ dá»¯ liá»‡u |
| numpy | â‰¥1.24.0 | TÃ­nh toÃ¡n sá»‘ há»c |
| scikit-learn | â‰¥1.3.0 | ML algorithms |
| xgboost | â‰¥2.0.0 | XGBoost model |
| matplotlib | â‰¥3.7.0 | Visualization |
| seaborn | â‰¥0.13.0 | Statistical plots |
| streamlit | â‰¥1.29.0 | Web application |
| joblib | â‰¥1.3.0 | Model serialization |

---

##  HÆ°á»›ng Dáº«n CÃ i Äáº·t

### BÆ°á»›c 1: Clone Repository

```bash
git clone https://github.com/your-username/heart-disease-prediction.git
cd S26-65TTNT_Nhom7_DuDoanBenhTim
```

### BÆ°á»›c 2: Táº¡o Virtual Environment

**Windows:**
```powershell
python -m venv .venv
.venv\Scripts\activate
```

**macOS/Linux:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### BÆ°á»›c 3: CÃ i Äáº·t Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### BÆ°á»›c 4: Kiá»ƒm Tra CÃ i Äáº·t

```python
python -c "import sklearn, xgboost, streamlit; print('All packages installed successfully!')"
```

---

## HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### Workflow Äáº§y Äá»§ (Cháº¡y Láº§n Äáº§u)

Cháº¡y cÃ¡c script theo thá»© tá»± sau:

#### 1ï¸ Tiá»n Xá»­ LÃ½ Dá»¯ Liá»‡u

```bash
python src/preprocessing.py
```

**Output:**
- `saved_models/eda_dataset.pkl` (Dá»¯ liá»‡u cho EDA)
- `saved_models/X_train.pkl`, `X_test.pkl`, `y_train.pkl`, `y_test.pkl`
- `saved_models/scaler.pkl`, `imputer.pkl`, `feature_columns.pkl`
- `outputs/preprocessing_log.txt`

**Káº¿t quáº£:**
- Train: 734 samples, Test: 184 samples
- 11 â†’ 17 features sau feature engineering
- Xá»­ lÃ½ 172 missing values (Cholesterol) vÃ  1 missing value (Huyáº¿t Ãp)

#### 2ï¸ PhÃ¢n TÃ­ch KhÃ¡m PhÃ¡ Dá»¯ Liá»‡u (EDA)

```bash
python src/eda.py
```

**Output:**
- `outputs/figures/1_Target.png` (PhÃ¢n bá»‘ target)
- `outputs/figures/Num_*.png` (Biá»ƒu Ä‘á»“ biáº¿n sá»‘)
- `outputs/figures/Cat_*.png` (Biá»ƒu Ä‘á»“ biáº¿n phÃ¢n loáº¡i)
- `outputs/figures/Correlation_Matrix.png`
- `outputs/eda_log.txt`

**PhÃ¡t hiá»‡n chÃ­nh:**
- Äá»™_ChÃªnh_ST cÃ³ khÃ¡c biá»‡t lá»›n giá»¯a Khá»e (0.4) vÃ  Bá»‡nh (1.3)
- Nam giá»›i cÃ³ nguy cÆ¡ cao hÆ¡n: 63.2% vs Ná»¯ 25.9%
- Äau ngá»±c ASY cÃ³ nguy cÆ¡ ráº¥t cao: 79.0%

#### 3ï¸ Huáº¥n Luyá»‡n MÃ´ HÃ¬nh

**Random Forest (Nguyá»…n LÃª Minh Háº­u):**
```bash
python src/RandomForest_NguyenLeMinhHau.py
```
- Grid Search: 180 fits (36 combinations Ã— 5 folds)
- Best Params: `n_estimators=200, max_depth=15, min_samples_leaf=2`
- Threshold: 0.5491
- Output: `saved_models/random_forest.pkl`, `outputs/figures/RF_*.png`

**XGBoost (Nguyá»…n LÃª Minh Háº­u):**
```bash
python src/XGBoost_NguyenLeMinhHau.py
```
- Grid Search: 180 fits (36 combinations Ã— 5 folds)
- Best Params: `learning_rate=0.01, max_depth=3, n_estimators=100`
- Threshold: 0.6711
- Output: `saved_models/xgboost.pkl`, `outputs/figures/XGBoost_*.png`

**Neural Network (Nguyá»…n Äá»©c Huy):**
```bash
python src/NeuralNetwork_NguyenDucHuy.py
```
- Grid Search: 90 fits (18 combinations Ã— 5 folds)
- Best Params: `hidden_layers=(64,32), alpha=0.0001, lr=0.001`
- Epochs: 39 (vá»›i Early Stopping)
- Threshold: 0.6184
- Output: `saved_models/neural_network.pkl`, `outputs/figures/NN_*.png`

#### 4ï¸ ÄÃ¡nh GiÃ¡ & So SÃ¡nh

```bash
python src/evaluation.py
```

**Output:**
- `outputs/figures/Comparison_*.png` (Biá»ƒu Ä‘á»“ so sÃ¡nh)
- `outputs/Evaluation_Report.txt` (BÃ¡o cÃ¡o chi tiáº¿t)
- `outputs/Evaluation_log.txt`

---

## Káº¿t Quáº£ Äáº¡t ÄÆ°á»£c

### Báº£ng So SÃ¡nh Hiá»‡u NÄƒng (Test Set: 184 samples)

| MÃ´ HÃ¬nh | Accuracy | Precision | Recall | F1-Score | AUC-ROC | FN (Bá» SÃ³t) |
|---------|----------|-----------|--------|----------|---------|--------------|
| **Random Forest** | **88.04%** | **85.09%** | 95.10% | **89.81%** | 92.32% | 5 |
| **XGBoost** | 82.07% | 77.17% | **96.08%** | 85.59% | 90.64% | **4**  |
| **Neural Network** | 86.96% | 84.21% | 94.12% | 88.89% | **94.49%** | 6 |

### Xáº¿p Háº¡ng MÃ´ HÃ¬nh

**TiÃªu chÃ­ xáº¿p háº¡ng:** Recall (Æ°u tiÃªn) > F1-Score > Accuracy

#### Háº¡ng 1: **XGBoost** (Khuyáº¿n nghá»‹ sá»­ dá»¥ng)
- **Recall: 96.08%** - PhÃ¡t hiá»‡n Ä‘Æ°á»£c 98/102 bá»‡nh nhÃ¢n
- **Bá» sÃ³t: 4 ngÆ°á»i** (tháº¥p nháº¥t)
- **Ã nghÄ©a:** Tá»‘t nháº¥t cho á»©ng dá»¥ng y táº¿ (Æ°u tiÃªn trÃ¡nh bá» sÃ³t)

#### Háº¡ng 2: **Random Forest**
- **Recall: 95.10%** - PhÃ¡t hiá»‡n Ä‘Æ°á»£c 97/102 bá»‡nh nhÃ¢n
- **F1-Score: 89.81%** (cao nháº¥t) - CÃ¢n báº±ng tá»‘t
- **Bá» sÃ³t: 5 ngÆ°á»i**

#### Háº¡ng 3: **Neural Network**
- **AUC-ROC: 94.49%** (cao nháº¥t) - Kháº£ nÄƒng phÃ¢n loáº¡i tá»•ng quÃ¡t tá»‘t
- **Recall: 94.12%** - PhÃ¡t hiá»‡n Ä‘Æ°á»£c 96/102 bá»‡nh nhÃ¢n
- **Bá» sÃ³t: 6 ngÆ°á»i**

### Confusion Matrix Chi Tiáº¿t

#### XGBoost (MÃ´ HÃ¬nh Tá»‘t Nháº¥t)
```
                Dá»± ÄoÃ¡n
              Khá»e  Bá»‡nh
Thá»±c  Khá»e     53    29
Táº¿    Bá»‡nh      4    98
```
- True Negatives (TN): 53 (28.8%)
- False Positives (FP): 29 (15.8%) - DÆ°Æ¡ng tÃ­nh giáº£
- False Negatives (FN): **4 (2.2%)** - Ã‚m tÃ­nh giáº£ 
- True Positives (TP): 98 (53.3%)

### Hidden Patterns (Top 3)

#### Pattern 1 (Random Forest - Nguy cÆ¡ 100%)
```
NEU:
  + Äá»™_Dá»‘c_ST_Up â‰¤ 0.50
  + Giá»›i_tÃ­nh > 0.50 (Nam)
  + Äá»™_ChÃªnh_ST â‰¤ -0.30 (ST Depression)
â†’ Nguy cÆ¡ bá»‡nh tim Ráº¤T CAO
â†’ Dá»±a trÃªn 51 bá»‡nh nhÃ¢n
```

#### Pattern 2 (XGBoost - Nguy cÆ¡ 92%)
```
NEU:
  + Äá»™_ChÃªnh_ST > 0.67
  + ÄÆ°á»ng_Huyáº¿t_ÄÃ³i > 0.00 (CÃ³ tiá»ƒu Ä‘Æ°á»ng)
â†’ Nguy cÆ¡ bá»‡nh tim Ráº¤T CAO
â†’ Dá»±a trÃªn 57 bá»‡nh nhÃ¢n
```

#### Pattern 3 (Neural Network - Nguy cÆ¡ 92%)
```
NEU:
  + Äá»™_ChÃªnh_ST > 0.95
â†’ Nguy cÆ¡ bá»‡nh tim Ráº¤T CAO
â†’ Dá»±a trÃªn 72 bá»‡nh nhÃ¢n
```

### Feature Importance (Top 5)

**Random Forest (Permutation):**
1. Äá»™_Dá»‘c_ST_Up: 0.0467
2. Äá»™_ChÃªnh_ST: 0.0283
3. Äá»™_Dá»‘c_ST_Flat: 0.0152
4. Äau_Tháº¯t_Váº­n_Äá»™ng: 0.0141
5. ÄÆ°á»ng_Huyáº¿t_ÄÃ³i: 0.0125

**XGBoost (Gain):**
1. Äá»™_Dá»‘c_ST_Up: 0.4431
2. Äá»™_ChÃªnh_ST: 0.0890
3. Äau_Tháº¯t_Váº­n_Äá»™ng: 0.0779
4. ÄÆ°á»ng_Huyáº¿t_ÄÃ³i: 0.0518
5. Loáº¡i_Äau_Ngá»±c_NAP: 0.0482

---

## ğŸŒ Demo Web Application

### Khá»Ÿi Cháº¡y Streamlit App

```bash
streamlit run src/app.py
```

á»¨ng dá»¥ng sáº½ má»Ÿ táº¡i: `http://localhost:8501`

### CÃ¡c TÃ­nh NÄƒng ChÃ­nh

1. **ğŸ  Trang Chá»§**
   - Giá»›i thiá»‡u dá»± Ã¡n
   - Workflow tá»•ng quan

2. **ğŸ“‚ Dá»¯ Liá»‡u & MÃ´ Táº£**
   - ThÃ´ng tin dataset
   - MÃ´ táº£ cÃ¡c Ä‘áº·c trÆ°ng

3. **ğŸ“Š PhÃ¢n TÃ­ch EDA**
   - Biá»ƒu Ä‘á»“ phÃ¢n bá»‘
   - Correlation matrix
   - Thá»‘ng kÃª mÃ´ táº£

4. **ğŸ”¬ So SÃ¡nh MÃ´ HÃ¬nh**
   - Báº£ng so sÃ¡nh metrics
   - ROC curves
   - Confusion matrices

5. **ğŸ©º Dá»± ÄoÃ¡n Nguy CÆ¡**
   - Nháº­p thÃ´ng tin bá»‡nh nhÃ¢n
   - Dá»± Ä‘oÃ¡n báº±ng 3 mÃ´ hÃ¬nh
   - Hiá»ƒn thá»‹ xÃ¡c suáº¥t chi tiáº¿t

6. **ğŸ” Hidden Patterns**
   - CÃ¡c máº«u áº©n Ä‘Ã£ phÃ¡t hiá»‡n
   - Quy luáº­t triá»‡u chá»©ng

7. **ğŸ“– HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng**
   - CÃ¡ch sá»­ dá»¥ng á»©ng dá»¥ng
   - Giáº£i thÃ­ch káº¿t quáº£

### Screenshot Demo

```
[HÃ¬nh áº£nh sáº½ Ä‘Æ°á»£c thÃªm sau khi cháº¡y app vÃ  chá»¥p mÃ n hÃ¬nh]
```

---

## ğŸ‘¥ ThÃ nh ViÃªn NhÃ³m

| STT | Há» TÃªn | MSSV | Nhiá»‡m Vá»¥ | ÄÃ³ng GÃ³p |
|-----|--------|------|----------|----------|
| 1 | **Nguyá»…n LÃª Minh Háº­u** | [2351267261] | **Team Lead & ML Engineer** | Random Forest, XGBoost, Pipeline Integration, Hidden Patterns Extraction |
| 2 | **Nguyá»…n Äá»©c Huy** | [2351267265] | **ML Engineer & Evaluator** | Neural Network, Model Evaluation, Comparison Analysis, Documentation |

### PhÃ¢n CÃ´ng Chi Tiáº¿t

#### Nguyá»…n LÃª Minh Háº­u
-  Random Forest: Hyperparameter tuning, Threshold optimization, Permutation importance
-  XGBoost: Grid search, Feature importance, Interaction analysis
-  Pipeline Integration: Káº¿t ná»‘i cÃ¡c module, workflow automation
-  Hidden Patterns: TrÃ­ch xuáº¥t quy luáº­t tá»« Random Forest vÃ  XGBoost
-  Code Review: Kiá»ƒm tra cháº¥t lÆ°á»£ng code

#### Nguyá»…n Äá»©c Huy
-  Neural Network: Architecture design, Early stopping, Learning curve analysis
-  Evaluation Module: So sÃ¡nh 3 mÃ´ hÃ¬nh, metrics visualization
-  Model Interpretability: Permutation importance cho NN
-  Hidden Patterns: PhÃ¢n tÃ­ch patterns tá»« Neural Network
-  Documentation: README, reports, code comments

#### Chung (Cáº£ NhÃ³m)
-  Preprocessing: Feature engineering, data cleaning (collaborative)
-  EDA: Exploratory data analysis, visualization
-  Streamlit App: Web application development
-  Testing & Debugging: Kiá»ƒm tra vÃ  sá»­a lá»—i

---

## Kiáº¿n Thá»©c Ãp Dá»¥ng

### Machine Learning
- Supervised Learning (Classification)
- Ensemble Methods (Random Forest, XGBoost)
- Neural Networks (MLPClassifier)
- Cross-Validation (K-Fold)
- Hyperparameter Tuning (Grid Search)
- Model Evaluation (Confusion Matrix, ROC, AUC)

### Data Science
- Data Preprocessing (Imputation, Scaling)
- Feature Engineering
- Exploratory Data Analysis (EDA)
- Data Visualization (Matplotlib, Seaborn)
- Statistical Analysis

### Software Engineering
- Modular Code Design
- Logging & Documentation
- Version Control (Git)
- Virtual Environments
- Web Application Development (Streamlit)

---


##  LÆ°u Ã Quan Trá»ng

### Giá»›i Háº¡n Sá»­ Dá»¥ng

 **Há»‡ thá»‘ng nÃ y CHá»ˆ MANG TÃNH CHáº¤T Há»ŒC Táº¬P VÃ€ NGHIÃŠN Cá»¨U.**

- **KHÃ”NG thay tháº¿** viá»‡c khÃ¡m, cháº©n Ä‘oÃ¡n vÃ  Ä‘iá»u trá»‹ y khoa chuyÃªn nghiá»‡p
- **KHÃ”NG tá»± Ã½** thay Ä‘á»•i phÃ¡c Ä‘á»“ Ä‘iá»u trá»‹ dá»±a trÃªn káº¿t quáº£ dá»± Ä‘oÃ¡n
- LuÃ´n tham kháº£o Ã½ kiáº¿n bÃ¡c sÄ© chuyÃªn khoa tim máº¡ch
- Káº¿t quáº£ dá»± Ä‘oÃ¡n cÃ³ thá»ƒ sai lá»‡ch (False Negatives váº«n tá»“n táº¡i)

### Khuyáº¿n Nghá»‹ PhÃ¡t Triá»ƒn

 **CÃ¡c cáº£i tiáº¿n trong tÆ°Æ¡ng lai:**

1. **Dataset lá»›n hÆ¡n:** Thu tháº­p thÃªm dá»¯ liá»‡u tá»« bá»‡nh viá»‡n táº¡i Viá»‡t Nam
2. **Ensemble Voting:** Káº¿t há»£p 3 mÃ´ hÃ¬nh báº±ng Soft Voting
3. **SHAP Values:** Giáº£i thÃ­ch chi tiáº¿t hÆ¡n cho tá»«ng dá»± Ä‘oÃ¡n
4. **Production Deployment:** Dockerize vÃ  deploy lÃªn cloud (AWS, GCP)
5. **Mobile App:** PhÃ¡t triá»ƒn á»©ng dá»¥ng di Ä‘á»™ng (React Native / Flutter)
6. **Real-time Monitoring:** TÃ­ch há»£p vá»›i thiáº¿t bá»‹ Ä‘o y táº¿ (wearable devices)

---


##  ÄÃ³ng GÃ³p & LiÃªn Há»‡

### BÃ¡o Lá»—i (Bug Report)

Náº¿u phÃ¡t hiá»‡n lá»—i, vui lÃ²ng táº¡o [Issue](https://github.com/your-repo/issues) vá»›i thÃ´ng tin:
- MÃ´ táº£ lá»—i chi tiáº¿t
- CÃ¡c bÆ°á»›c tÃ¡i hiá»‡n
- Screenshot (náº¿u cÃ³)
- Environment (OS, Python version)



## ğŸ“ Phá»¥ Lá»¥c

### A. CÃ¡c Lá»‡nh Nhanh (Quick Commands)

```bash
# Cháº¡y toÃ n bá»™ pipeline
python src/preprocessing.py && \
python src/eda.py && \
python src/RandomForest_NguyenLeMinhHau.py && \
python src/XGBoost_NguyenLeMinhHau.py && \
python src/NeuralNetwork_NguyenDucHuy.py && \
python src/evaluation.py

# Khá»Ÿi Ä‘á»™ng web app
streamlit run src/app.py

# Táº¡o bÃ¡o cÃ¡o Word (náº¿u cÃ³)
python generate_report.py
```

### B. Troubleshooting

**Lá»—i: "No module named 'sklearn'"**
```bash
pip install scikit-learn
```

**Lá»—i: "FileNotFoundError: [Errno 2] No such file or directory: 'data/heart.csv'"**
- Kiá»ƒm tra file `heart.csv` cÃ³ tá»“n táº¡i trong thÆ° má»¥c `data/`
- Äáº£m báº£o Ä‘ang cháº¡y lá»‡nh tá»« thÆ° má»¥c gá»‘c cá»§a dá»± Ã¡n

**Streamlit App khÃ´ng khá»Ÿi Ä‘á»™ng:**
```bash
# Kiá»ƒm tra port 8501 Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng chÆ°a
streamlit run src/app.py --server.port 8502
```

### C. Environment Variables

Náº¿u cáº§n tÃ¹y chá»‰nh, táº¡o file `.env`:

```env
# ÄÆ°á»ng dáº«n dataset
DATA_PATH=data/heart.csv

# Random seed
RANDOM_STATE=2026

# Test size
TEST_SIZE=0.2
```

---

** Cáº£m Æ¡n báº¡n Ä‘Ã£ quan tÃ¢m Ä‘áº¿n dá»± Ã¡n cá»§a chÃºng tÃ´i! **
