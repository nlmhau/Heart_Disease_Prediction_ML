# ============================================================
# RANDOM_FOREST.PY
# Nguy·ªÖn L√™ Minh H·∫≠u
# M·ª•c ti√™u:
#   - Hu·∫•n luy·ªán Random Forest v·ªõi Hyperparameter Tuning
#   - T·ªëi ∆∞u ng∆∞·ª°ng d·ª± ƒëo√°n (Threshold Tuning)
#   - ƒê√°nh gi√° m√¥ h√¨nh theo h∆∞·ªõng y t·∫ø (∆∞u ti√™n Recall)
#   - Gi·∫£i th√≠ch m√¥ h√¨nh b·∫±ng Permutation Importance
#   - Tr√≠ch xu·∫•t & minh h·ªça lu·∫≠t t·ª´ c√¢y quy·∫øt ƒë·ªãnh ƒë·∫°i di·ªán
# ============================================================

import os
import joblib
import numpy as np
import pandas as pd

# ƒê·∫∑t backend matplotlib tr∆∞·ªõc khi import pyplot (tr√°nh l·ªói tkinter)
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import (
    classification_report,
    roc_auc_score,
    roc_curve,
    confusion_matrix,
    precision_recall_curve
)
from sklearn.inspection import permutation_importance
from sklearn.tree import export_text, plot_tree

warnings.filterwarnings("ignore")


# ============================================================
# I. C·∫§U H√åNH & LOAD D·ªÆ LI·ªÜU
# ============================================================

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SAVED_MODELS_DIR = os.path.join(BASE_DIR, "../saved_models")
FIGURES_DIR = os.path.join(BASE_DIR, "../outputs/figures")
OUTPUTS_DIR = os.path.join(BASE_DIR, "../outputs")

os.makedirs(FIGURES_DIR, exist_ok=True)
os.makedirs(OUTPUTS_DIR, exist_ok=True)

# Logger: In console + ghi file
class Logger:
    def __init__(self, log_file):
        self.log_file = open(log_file, 'w', encoding='utf-8')
    
    def log(self, message=""):
        print(message)
        self.log_file.write(message + '\n')
        self.log_file.flush()
    
    def close(self):
        self.log_file.close()

logger = Logger(os.path.join(OUTPUTS_DIR, "RandomForest_log.txt"))

logger.log("=" * 60)
logger.log("I. LOAD D·ªÆ LI·ªÜU & CHU·∫®N B·ªä")
logger.log("=" * 60)

try:
    X_train = joblib.load(os.path.join(SAVED_MODELS_DIR, "X_train.pkl"))
    X_test  = joblib.load(os.path.join(SAVED_MODELS_DIR, "X_test.pkl"))
    y_train = joblib.load(os.path.join(SAVED_MODELS_DIR, "y_train.pkl"))
    y_test  = joblib.load(os.path.join(SAVED_MODELS_DIR, "y_test.pkl"))
    feature_names = X_train.columns.tolist()
    logger.log(f" ƒê√£ load d·ªØ li·ªáu: Train {X_train.shape}, Test {X_test.shape}")
except FileNotFoundError:
    logger.log(" L·ªói: Ch∆∞a c√≥ d·ªØ li·ªáu ti·ªÅn x·ª≠ l√Ω. H√£y ch·∫°y preprocessing.py tr∆∞·ªõc.")
    logger.close()
    exit()

# ============================================================
# II. HU·∫§N LUY·ªÜN & HYPERPARAMETER TUNING
# ============================================================

logger.log("\n" + "=" * 60)
logger.log("II. HU·∫§N LUY·ªÜN & HYPERPARAMETER TUNING (GRID SEARCH)")
logger.log("=" * 60)

param_grid = {
    "n_estimators": [100, 200, 300],
    "max_depth": [10, 15, 20, None],
    "min_samples_leaf": [1, 2, 4]
}

rf = RandomForestClassifier(
    random_state=2026,
    n_jobs=-1
)

grid_search = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    scoring="recall",     # ∆Øu ti√™n ph√°t hi·ªán ng∆∞·ªùi b·ªánh
    cv=5,
    n_jobs=1,
    verbose=1
)

logger.log(" ƒêang t√¨m ki·∫øm hyperparameters t·ªët nh·∫•t...")
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_

logger.log(f"\n Ho√†n th√†nh Grid Search!")
logger.log(f"   Best Params: {grid_search.best_params_}")
logger.log(f"   Best Recall (CV): {grid_search.best_score_:.4f}")

# ============================================================
# III. THRESHOLD TUNING (OPTIMIZE DECISION BOUNDARY)
# ============================================================

logger.log("\n" + "=" * 60)
logger.log("III. T·ªêI ∆ØU NG∆Ø·ª†NG D·ª∞ ƒêO√ÅN (THRESHOLD TUNING)")
logger.log("=" * 60)

y_probs = best_model.predict_proba(X_test)[:, 1]

precisions, recalls, thresholds = precision_recall_curve(y_test, y_probs)
f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)

best_idx = np.argmax(f1_scores)
best_threshold = thresholds[best_idx]

logger.log(f" Ng∆∞·ª°ng t·ªëi ∆∞u: {best_threshold:.4f}")
logger.log(f"   ‚Üí Precision={precisions[best_idx]:.4f} | Recall={recalls[best_idx]:.4f}")

y_pred = (y_probs >= best_threshold).astype(int)

logger.log("\n" + "=" * 60)
logger.log("K·∫æT QU·∫¢ TR√äN T·∫¨P TEST")
logger.log("=" * 60)
logger.log(classification_report(y_test, y_pred, target_names=["Kh·ªèe", "B·ªánh"], digits=4))
logger.log(f"\n AUC-ROC Score: {roc_auc_score(y_test, y_probs):.4f}")

# Confusion Matrix chi ti·∫øt
cm = confusion_matrix(y_test, y_pred)
tn, fp, fn, tp = cm.ravel()
logger.log(f"\n Confusion Matrix:")
logger.log(f"   - True Negatives (TN): {tn} (D·ª± ƒëo√°n ƒë√∫ng ng∆∞·ªùi kh·ªèe)")
logger.log(f"   - False Positives (FP): {fp} (D·ª± ƒëo√°n nh·∫ßm ng∆∞·ªùi kh·ªèe th√†nh b·ªánh)")
logger.log(f"   - False Negatives (FN): {fn}  (B·ªé S√ìT ng∆∞·ªùi b·ªánh - quan tr·ªçng!)")
logger.log(f"   - True Positives (TP): {tp} (D·ª± ƒëo√°n ƒë√∫ng ng∆∞·ªùi b·ªánh)")

# ============================================================
# IV. BI·ªÇU ƒê·ªí ƒê√ÅNH GI√Å
# ============================================================

logger.log("\n" + "=" * 60)
logger.log("IV. T·∫†O BI·ªÇU ƒê·ªí ƒê√ÅNH GI√Å")
logger.log("=" * 60)

# ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_probs)
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label=f"AUC = {roc_auc_score(y_test, y_probs):.4f}", linewidth=2)
plt.plot([0, 1], [0, 1], "k--", alpha=0.3)
plt.xlabel("False Positive Rate (T·ª∑ l·ªá d∆∞∆°ng t√≠nh gi·∫£)", fontsize=11)
plt.ylabel("True Positive Rate (T·ª∑ l·ªá d∆∞∆°ng t√≠nh th·∫≠t)", fontsize=11)
plt.title("ROC Curve ‚Äì Random Forest", fontsize=13, fontweight='bold')
plt.legend(fontsize=11)
plt.grid(True, alpha=0.3)
plt.savefig(os.path.join(FIGURES_DIR, "RF_ROC.png"), dpi=150)
plt.close()
logger.log("   ƒê√£ l∆∞u: RF_ROC.png")

# Confusion Matrix
plt.figure(figsize=(7, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=True,
            xticklabels=["Kh·ªèe", "B·ªánh"],
            yticklabels=["Kh·ªèe", "B·ªánh"],
            annot_kws={"fontsize": 14})
plt.title(f"Confusion Matrix (Ng∆∞·ª°ng = {best_threshold:.3f})", fontsize=13, fontweight='bold')
plt.ylabel("Th·ª±c t·∫ø", fontsize=11)
plt.xlabel("D·ª± ƒëo√°n", fontsize=11)
plt.savefig(os.path.join(FIGURES_DIR, "RF_Confusion_Matrix.png"), dpi=150)
plt.close()
logger.log("   ƒê√£ l∆∞u: RF_Confusion_Matrix.png")

# ============================================================
# V. GI·∫¢I TH√çCH M√î H√åNH (PERMUTATION IMPORTANCE)
# ============================================================

logger.log("\n" + "=" * 60)
logger.log("V. PH√ÇN T√çCH ƒê·ªò QUAN TR·ªåNG ƒê·∫∂C TR∆ØNG (PERMUTATION)")
logger.log("=" * 60)

logger.log("üî¨ ƒêang t√≠nh to√°n Permutation Importance...")
perm = permutation_importance(
    best_model, X_test, y_test,
    n_repeats=10,
    random_state=2026,
    n_jobs=-1
)

sorted_idx = perm.importances_mean.argsort()[::-1]

df_imp = pd.DataFrame({
    "ƒê·∫∑c tr∆∞ng": np.array(feature_names)[sorted_idx],
    "ƒê·ªô quan tr·ªçng": perm.importances_mean[sorted_idx]
})

logger.log("\n Top 10 ƒë·∫∑c tr∆∞ng ·∫£nh h∆∞·ªüng nh·∫•t:")
for idx, row in df_imp.head(10).iterrows():
    logger.log(f"   {idx+1}. {row['ƒê·∫∑c tr∆∞ng']:<25} ‚Üí {row['ƒê·ªô quan tr·ªçng']:.4f}")

plt.figure(figsize=(10, 8))
plt.barh(df_imp["ƒê·∫∑c tr∆∞ng"][:10], df_imp["ƒê·ªô quan tr·ªçng"][:10], color='#3498db')
plt.gca().invert_yaxis()
plt.title("Top 10 ƒê·∫∑c Tr∆∞ng Quan Tr·ªçng Nh·∫•t (Permutation Importance)", 
          fontsize=13, fontweight='bold')
plt.xlabel("M·ª©c ƒë·ªô gi·∫£m ƒë·ªô ch√≠nh x√°c khi x√°o tr·ªôn", fontsize=11)
plt.ylabel("ƒê·∫∑c tr∆∞ng", fontsize=11)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.savefig(os.path.join(FIGURES_DIR, "RF_Permutation_Importance.png"), dpi=150)
plt.close()
logger.log("    ƒê√£ l∆∞u: RF_Permutation_Importance.png")

# ============================================================
# VI. TR√çCH XU·∫§T & MINH H·ªåA LU·∫¨T
# ============================================================

logger.log("\n" + "=" * 60)
logger.log("VI. TR√çCH XU·∫§T LU·∫¨T T·ª™ C√ÇY QUY·∫æT ƒê·ªäNH ƒê·∫†I DI·ªÜN")
logger.log("=" * 60)

one_tree = best_model.estimators_[0]

tree_rules = export_text(
    one_tree,
    feature_names=feature_names,
    max_depth=5  # Ch·ªâ hi·ªÉn th·ªã 5 t·∫ßng ƒë·∫ßu cho d·ªÖ ƒë·ªçc
)
logger.log("\n Lu·∫≠t quy·∫øt ƒë·ªãnh (5 t·∫ßng ƒë·∫ßu):")
logger.log(tree_rules)

logger.log("\n ƒêang t·∫°o bi·ªÉu ƒë·ªì c√¢y quy·∫øt ƒë·ªãnh...")
plt.figure(figsize=(24, 14))
plot_tree(
    one_tree,
    feature_names=feature_names,
    class_names=["Kh·ªèe", "B·ªánh"],
    filled=True,
    rounded=True,
    max_depth=3,  # Gi·ªõi h·∫°n depth ƒë·ªÉ d·ªÖ nh√¨n
    fontsize=10
)
plt.title("C√¢y Quy·∫øt ƒê·ªãnh ƒê·∫°i Di·ªán (Random Forest - ƒê·ªô s√¢u 3 t·∫ßng)", 
          fontsize=14, fontweight='bold')
plt.savefig(os.path.join(FIGURES_DIR, "RF_Decision_Tree.png"),
            dpi=150, bbox_inches="tight")
plt.close()
logger.log("    ƒê√£ l∆∞u: RF_Decision_Tree.png")

# ============================================================
# VII. PH√ÅT HI·ªÜN M·∫™U ·∫®N (HIDDEN PATTERNS)
# ============================================================

logger.log("\n" + "=" * 60)
logger.log("VII. PH√ÅT HI·ªÜN M·∫™U ·∫®N (HIDDEN PATTERNS)")
logger.log("=" * 60)
logger.log(" Tr√≠ch xu·∫•t c√°c quy lu·∫≠t: Tri·ªáu ch·ª©ng A + B + C ‚Üí B·ªánh Tim")

def extract_rules_from_tree(tree, feature_names, max_rules=10):
    """Tr√≠ch xu·∫•t quy lu·∫≠t IF-THEN d·ªÖ hi·ªÉu t·ª´ c√¢y quy·∫øt ƒë·ªãnh"""
    tree_ = tree.tree_
    feature_name = [feature_names[i] if i != -2 else "undefined" 
                   for i in tree_.feature]
    
    rules = []
    
    def recurse(node, conditions, depth=0):
        if depth > 4:  # Gi·ªõi h·∫°n ƒë·ªô s√¢u
            return
        
        if tree_.feature[node] != -2:  # Kh√¥ng ph·∫£i l√°
            feature = feature_name[node]
            threshold = tree_.threshold[node]
            
            # Nh√°nh tr√°i (<=)
            left_conditions = conditions + [(feature, "<=", threshold)]
            recurse(tree_.children_left[node], left_conditions, depth + 1)
            
            # Nh√°nh ph·∫£i (>)
            right_conditions = conditions + [(feature, ">", threshold)]
            recurse(tree_.children_right[node], right_conditions, depth + 1)
        else:
            # L√°: t√≠nh x√°c su·∫•t
            samples = tree_.n_node_samples[node]
            value = tree_.value[node][0]
            disease_prob = value[1] / (value[0] + value[1]) if (value[0] + value[1]) > 0 else 0
            
            # L·∫•y quy lu·∫≠t d·ª± ƒëo√°n b·ªánh v·ªõi nhi·ªÅu m·ª©c ƒë·ªô r·ªßi ro kh√°c nhau
            if disease_prob >= 0.30 and samples >= 3:
                rules.append({
                    'conditions': conditions,
                    'disease_prob': disease_prob,
                    'samples': samples,
                    'depth': len(conditions)
                })
    
    recurse(0, [])
    
    # S·∫Øp x·∫øp theo: ƒë·ªô tin c·∫≠y ‚Üí s·ªë m·∫´u ‚Üí ƒë·ªô s√¢u
    rules.sort(key=lambda x: (-x['disease_prob'], -x['samples'], x['depth']))
    return rules[:max_rules]

def interpret_condition(feature, operator, threshold):
    """Chuy·ªÉn ƒëi·ªÅu ki·ªán k·ªπ thu·∫≠t th√†nh ng√¥n ng·ªØ y khoa"""
    # √Ånh x·∫° t√™n ƒë·∫∑c tr∆∞ng sang gi·∫£i th√≠ch
    interpretations = {
        "Tuoi": "Tuoi",
        "Gioi_tinh": "Nam gioi" if operator == ">" else "Nu gioi",
        "Cholesterol": "Cholesterol",
        "Huyet_Ap_Nghi": "Huyet ap nghi",
        "Duong_Huyet_Doi": "Duong huyet doi cao" if operator == ">" else "Duong huyet doi thap",
        "Nhip_Tim_Toi_Da": "Nhip tim toi da",
        "Dau_That_Van_Dong": "Co dau that vung nguc khi van dong" if operator == ">" else "Khong dau that khi van dong",
        "Do_Chenh_ST": "Do chenh ST",
        "Do_Doc_ST_Up": "Do doc ST len" if operator == ">" else "Do doc ST khong len",
        "Do_Doc_ST_Flat": "Do doc ST phang" if operator == ">" else "Do doc ST khong phang",
        "Cholesterol_Tuoi": "Ty le Cholesterol/Tuoi",
    }
    
    # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho m·ªôt s·ªë bi·∫øn
    if feature == "Gioi_tinh":
        return "Nam gioi" if operator == ">" else "Nu gioi"
    elif feature == "Duong_Huyet_Doi":
        return "Duong huyet doi cao" if operator == ">" else "Duong huyet doi binh thuong"
    elif feature == "Dau_That_Van_Dong":
        return "Dau that vung nguc khi van dong" if operator == ">" else "Khong dau that vung nguc"
    elif feature in ["Do_Doc_ST_Up", "Do_Doc_ST_Flat"]:
        return interpretations.get(feature, feature)
    else:
        # C√°c bi·∫øn li√™n t·ª•c: hi·ªÉn th·ªã ng∆∞·ª°ng
        op_str = ">" if operator == ">" else "<="
        return f"{feature} {op_str} {threshold:.2f}"

# Tr√≠ch xu·∫•t t·ª´ NHI·ªÄU c√¢y trong Random Forest (kh√¥ng ch·ªâ 1 c√¢y)
all_rules = []
num_trees_to_check = min(50, len(best_model.estimators_))  # Ki·ªÉm tra 50 c√¢y

logger.log(f"\n Dang trich xuat quy luat tu {num_trees_to_check} cay trong Random Forest...")

for tree_idx in range(num_trees_to_check):
    tree = best_model.estimators_[tree_idx]
    tree_rules = extract_rules_from_tree(tree, feature_names, max_rules=10)
    all_rules.extend(tree_rules)

# Lo·∫°i b·ªè quy lu·∫≠t tr√πng l·∫∑p v√† s·∫Øp x·∫øp l·∫°i
unique_rules = []
seen_conditions = set()

for rule in all_rules:
    # T·∫°o signature t·ª´ ƒëi·ªÅu ki·ªán
    cond_str = str(sorted(rule['conditions']))
    if cond_str not in seen_conditions:
        seen_conditions.add(cond_str)
        unique_rules.append(rule)

# S·∫Øp x·∫øp theo ƒë·ªô tin c·∫≠y v√† s·ªë m·∫´u
unique_rules.sort(key=lambda x: (-x['disease_prob'], -x['samples'], x['depth']))

logger.log(f" Trich xuat duoc {len(unique_rules)} quy luat benh tim tu {num_trees_to_check} cay")

# Hi·ªÉn th·ªã 5 m·∫´u: Top 3 cao nh·∫•t + 2 th·∫•p nh·∫•t (ƒë·ªÉ th·∫•y s·ª± ƒëa d·∫°ng)
display_rules = []

# L·∫•y top 3 m·∫´u r·ªßi ro CAO NH·∫§T
top_high = unique_rules[:3]
for rule in top_high:
    display_rules.append((rule, f"Rat cao ({rule['disease_prob']*100:.0f}%)"))

# L·∫•y 2 m·∫´u r·ªßi ro TH·∫§P NH·∫§T (nh∆∞ng v·∫´n >30%)
bottom_2 = sorted(unique_rules, key=lambda x: x['disease_prob'])[:2]
for rule in bottom_2:
    display_rules.append((rule, f"Trung binh ({rule['disease_prob']*100:.0f}%)"))

logger.log(f" Hien thi {len(display_rules)} mau dai dien (3 cao nhat + 2 thap nhat):")
logger.log()

for i, (rule, risk_label) in enumerate(display_rules, 1):
    conditions_text = []
    for feat, op, thresh in rule['conditions']:
        cond_str = interpret_condition(feat, op, thresh)
        conditions_text.append(cond_str)
    
    # Hi·ªÉn th·ªã t·∫•t c·∫£ ƒëi·ªÅu ki·ªán quan tr·ªçng
    logger.log(f"{i}. NEU:")
    for cond in conditions_text:
        logger.log(f"      + {cond}")
    logger.log(f"   ‚Üí KET LUAN: Nguy co benh tim {risk_label}")
    logger.log(f"   ‚Üí Can cu: {rule['samples']} benh nhan trong tap huan luyen")
    logger.log()
    logger.log()

# ============================================================
# VIII. L∆ØU M√î H√åNH
# ============================================================

logger.log("\n" + "=" * 60)
logger.log("VIII. LUU MO HINH")
logger.log("=" * 60)

joblib.dump(best_model, os.path.join(SAVED_MODELS_DIR, "random_forest.pkl"))
logger.log(" ƒê√£ l∆∞u m√¥ h√¨nh Random Forest: random_forest.pkl")

# L∆∞u metadata
metadata = {
    'threshold': best_threshold,
    'best_params': grid_search.best_params_,
    'cv_recall': grid_search.best_score_,
    'test_accuracy': (y_pred == y_test).mean(),
    'test_recall': recalls[best_idx],
    'auc_roc': roc_auc_score(y_test, y_probs)
}
joblib.dump(metadata, os.path.join(SAVED_MODELS_DIR, "rf_metadata.pkl"))
logger.log(" ƒê√£ l∆∞u metadata: rf_metadata.pkl")

logger.log("\n" + "=" * 60)
logger.log(" HO√ÄN TH√ÄNH!")
logger.log("=" * 60)
logger.log(f" T√≥m t·∫Øt k·∫øt qu·∫£:")
logger.log(f"   - Ng∆∞·ª°ng t·ªëi ∆∞u: {best_threshold:.4f}")
logger.log(f"   - Test Accuracy: {metadata['test_accuracy']:.4f}")
logger.log(f"   - Test Recall: {metadata['test_recall']:.4f}")
logger.log(f"   - AUC-ROC: {metadata['auc_roc']:.4f}")
logger.log(f"   - False Negatives: {fn} (B·ªè s√≥t {fn} b·ªánh nh√¢n)")
logger.log(f"\n C√°c file output ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {FIGURES_DIR}")
logger.log(f" File log ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {os.path.join(OUTPUTS_DIR, 'RandomForest_log.txt')}")

logger.close()
