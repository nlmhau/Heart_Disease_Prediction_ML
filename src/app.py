# ============================================================
# APP.PY ‚Äì DASHBOARD D·ª∞ ƒêO√ÅN B·ªÜNH TIM
# Nh√≥m 7 - S26-65TTNT
# M·ª•c ti√™u:
#   - T·∫£i d·ªØ li·ªáu ho·∫∑c ch·ªçn file m·∫´u
#   - Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì ph√¢n t√≠ch (EDA)
#   - Cho ph√©p nh·∫≠p input v√† hi·ªÉn th·ªã d·ª± ƒëo√°n
#   - So s√°nh 3 m√¥ h√¨nh: Random Forest, XGBoost, Neural Network
#   - Hi·ªÉn th·ªã Hidden Patterns ƒë∆∞·ª£c ph√°t hi·ªán
# ============================================================

import streamlit as st
import pandas as pd
import joblib
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
from PIL import Image

# ============================================================
# 0. C·∫§U H√åNH GIAO DI·ªÜN
# ============================================================

st.set_page_config(
    page_title="Dashboard D·ª± ƒêo√°n B·ªánh Tim",
    page_icon="ü´Ä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS t√πy ch·ªânh
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #e74c3c;
        text-align: center;
        padding: 1rem;
        background: linear-gradient(90deg, #f8f9fa 0%, #ffffff 100%);
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        border-left: 5px solid #3498db;
    }
    .warning-box {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 1rem;
        border-radius: 5px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

st.markdown('<div class="main-header">ü´Ä DASHBOARD D·ª∞ ƒêO√ÅN NGUY C∆† B·ªÜNH TIM</div>', unsafe_allow_html=True)

st.markdown("""
<div class="warning-box">
    <strong>‚ö†Ô∏è L∆ØU √ù:</strong> ·ª®ng d·ª•ng n√†y ch·ªâ mang t√≠nh ch·∫•t h·ªó tr·ª£ nghi√™n c·ª©u v√† minh h·ªça khoa h·ªçc. 
    <strong>KH√îNG THAY TH·∫æ</strong> vi·ªác ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã y khoa chuy√™n nghi·ªáp.
</div>
""", unsafe_allow_html=True)

# ============================================================
# 1. LOAD PIPELINE & MODELS (Cache ƒë·ªÉ t·ªëi ∆∞u performance)
# ============================================================

@st.cache_resource
def load_all_resources():
    """
    Load t·∫•t c·∫£ m√¥ h√¨nh, scaler, imputer v√† d·ªØ li·ªáu
    Cache ƒë·ªÉ tr√°nh load l·∫°i m·ªói l·∫ßn user t∆∞∆°ng t√°c
    """
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    SAVED_MODELS_DIR = os.path.join(BASE_DIR, "../saved_models")
    FIGURES_DIR = os.path.join(BASE_DIR, "../outputs/figures")
    
    # Load 3 m√¥ h√¨nh
    rf_model = joblib.load(os.path.join(SAVED_MODELS_DIR, "random_forest.pkl"))
    xgb_model = joblib.load(os.path.join(SAVED_MODELS_DIR, "xgboost.pkl"))
    nn_model = joblib.load(os.path.join(SAVED_MODELS_DIR, "neural_network.pkl"))
    
    # Load metadata
    rf_meta = joblib.load(os.path.join(SAVED_MODELS_DIR, "rf_metadata.pkl"))
    xgb_meta = joblib.load(os.path.join(SAVED_MODELS_DIR, "xgboost_metadata.pkl"))
    nn_meta = joblib.load(os.path.join(SAVED_MODELS_DIR, "nn_metadata.pkl"))
    
    # Load preprocessing tools
    scaler = joblib.load(os.path.join(SAVED_MODELS_DIR, "scaler.pkl"))
    imputer = joblib.load(os.path.join(SAVED_MODELS_DIR, "imputer.pkl"))
    feature_cols = joblib.load(os.path.join(SAVED_MODELS_DIR, "feature_columns.pkl"))
    
    # Load datasets
    eda_df = joblib.load(os.path.join(SAVED_MODELS_DIR, "eda_dataset.pkl"))
    X_test = joblib.load(os.path.join(SAVED_MODELS_DIR, "X_test.pkl"))
    y_test = joblib.load(os.path.join(SAVED_MODELS_DIR, "y_test.pkl"))
    
    return {
        'models': {'rf': rf_model, 'xgb': xgb_model, 'nn': nn_model},
        'metadata': {'rf': rf_meta, 'xgb': xgb_meta, 'nn': nn_meta},
        'preprocessing': {'scaler': scaler, 'imputer': imputer, 'feature_cols': feature_cols},
        'data': {'eda_df': eda_df, 'X_test': X_test, 'y_test': y_test},
        'dirs': {'figures': FIGURES_DIR}
    }

# Load t·∫•t c·∫£ resources
try:
    resources = load_all_resources()
    models = resources['models']
    metadata = resources['metadata']
    scaler = resources['preprocessing']['scaler']
    imputer = resources['preprocessing']['imputer']
    feature_cols = resources['preprocessing']['feature_cols']
    eda_df = resources['data']['eda_df']
    X_test = resources['data']['X_test']
    y_test = resources['data']['y_test']
    FIGURES_DIR = resources['dirs']['figures']
except Exception as e:
    st.error(f"‚ùå L·ªói khi load m√¥ h√¨nh: {e}")
    st.info("üí° H√£y ch·∫°y c√°c file preprocessing.py ‚Üí models ‚Üí evaluation.py tr∆∞·ªõc!")
    st.stop()

# ============================================================
# 2. SIDEBAR - MENU ƒêI·ªÄU H∆Ø·ªöNG
# ============================================================

st.sidebar.title("üìã MENU ƒêI·ªÄU H∆Ø·ªöNG")
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "Ch·ªçn ch·ª©c nƒÉng:",
    [
        "üè† Trang ch·ªß",
        "üìÇ D·ªØ li·ªáu & M√¥ t·∫£",
        "üìä Ph√¢n t√≠ch EDA",
        "üî¨ So s√°nh m√¥ h√¨nh",
        "ü©∫ D·ª± ƒëo√°n nguy c∆°",
        "üîç Hidden Patterns",
        "üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng"
    ]
)

st.sidebar.markdown("---")
st.sidebar.info("""
**Nh√≥m 7 - S26-65TTNT**
- Nguy·ªÖn L√™ Minh H·∫≠u
- Nguy·ªÖn ƒê·ª©c Huy

**ƒê·ªì √°n m√¥n:** Machine Learning
""")

# ============================================================
# 3. TRANG CH·ª¶
# ============================================================

if page == "üè† Trang ch·ªß":
    st.header("üè† T·ªîNG QUAN D·ª∞ √ÅN")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>üìä D·ªØ li·ªáu</h3>
            <p><strong>918</strong> b·ªánh nh√¢n</p>
            <p><strong>17</strong> ƒë·∫∑c tr∆∞ng</p>
            <p><strong>55.3%</strong> t·ª∑ l·ªá b·ªánh</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>ü§ñ M√¥ h√¨nh</h3>
            <p><strong>3</strong> m√¥ h√¨nh ML</p>
            <p><strong>96.08%</strong> Recall t·ªët nh·∫•t</p>
            <p><strong>XGBoost</strong> hi·ªáu qu·∫£ nh·∫•t</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3>üéØ M·ª•c ti√™u</h3>
            <p>Ph√°t hi·ªán s·ªõm</p>
            <p>Gi·∫£m b·ªè s√≥t</p>
            <p>H·ªó tr·ª£ quy·∫øt ƒë·ªãnh</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    st.subheader("üìå Quy tr√¨nh x·ª≠ l√Ω d·ªØ li·ªáu")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("""
        ### Pipeline x·ª≠ l√Ω:
        
        1. **Preprocessing (preprocessing.py)**
           - X·ª≠ l√Ω missing values (Cholesterol: 172, BP: 1)
           - Gi·ªØ nguy√™n Oldpeak √¢m (√Ω nghƒ©a y khoa)
           - Chia Train/Test (80/20 stratified)
           - Encoding (Label + One-Hot)
           - Iterative Imputer
           - Feature Engineering (Cholesterol_Tuoi, NguyCo_TimMach_RatCao)
           - RobustScaler
        
        2. **EDA (eda.py)**
           - Ph√¢n t√≠ch bi·∫øn s·ªë (Mean Difference)
           - Ph√¢n t√≠ch bi·∫øn ph√¢n lo·∫°i (Risk Ratio)
           - Visualization (15 bi·ªÉu ƒë·ªì)
           - Ph√°t hi·ªán nh√≥m nguy c∆° cao
        
        3. **Modeling**
           - **Random Forest:** GridSearch 36 t·ªï h·ª£p, Threshold Tuning
           - **XGBoost:** Gradient Boosting, scale_pos_weight=2
           - **Neural Network:** MLP (64,32), Early Stopping
        
        4. **Evaluation (evaluation.py)**
           - So s√°nh 3 m√¥ h√¨nh
           - Ph√¢n t√≠ch Hidden Patterns
           - B√°o c√°o chi ti·∫øt
        """)
    
    with col2:
        st.markdown("""
        ### K·∫øt qu·∫£ ch√≠nh:
        
        **üèÜ M√¥ h√¨nh t·ªët nh·∫•t:** XGBoost
        - ‚úÖ Recall: 96.08%
        - ‚úÖ FN: 4 (√≠t nh·∫•t)
        - ‚úÖ 5 nh√≥m nguy c∆°
        - ‚úÖ 102 BN ph√°t hi·ªán
        
        **üìä So s√°nh:**
        - Random Forest: 95.10% Recall
        - Neural Network: 94.12% Recall
        
        **üîç Hidden Patterns:**
        - ƒê·ªô_Ch√™nh_ST > 0.67 ‚Üí 92%
        - Combo patterns: 2-3 tri·ªáu ch·ª©ng
        - Threshold c·ª• th·ªÉ cho t·ª´ng m·ª©c
        """)
    
    st.markdown("---")
    
    st.subheader("üéØ T√≠nh nƒÉng Dashboard")
    
    features_col1, features_col2 = st.columns(2)
    
    with features_col1:
        st.markdown("""
        ‚úÖ **T·∫£i & Xem d·ªØ li·ªáu:**
        - Upload file CSV ho·∫∑c d√πng file m·∫´u
        - Hi·ªÉn th·ªã th·ªëng k√™ m√¥ t·∫£
        - Gi·∫£i th√≠ch √Ω nghƒ©a c√°c c·ªôt
        
        ‚úÖ **Ph√¢n t√≠ch EDA:**
        - Bi·ªÉu ƒë·ªì ph√¢n b·ªë
        - Ma tr·∫≠n t∆∞∆°ng quan
        - Ph√¢n t√≠ch theo nh√≥m nguy c∆°
        """)
    
    with features_col2:
        st.markdown("""
        ‚úÖ **D·ª± ƒëo√°n nguy c∆°:**
        - Nh·∫≠p th√¥ng tin b·ªánh nh√¢n
        - D·ª± ƒëo√°n b·∫±ng 3 m√¥ h√¨nh
        - Hi·ªÉn th·ªã x√°c su·∫•t chi ti·∫øt
        
        ‚úÖ **Hidden Patterns:**
        - 15 m·∫´u ·∫©n t·ª´ 3 m√¥ h√¨nh
        - Threshold c·ª• th·ªÉ
        - Gi·∫£i th√≠ch y khoa
        """)

# ============================================================
# 4. D·ªÆ LI·ªÜU & M√î T·∫¢
# ============================================================

elif page == "üìÇ D·ªØ li·ªáu & M√¥ t·∫£":
    st.header("üìÇ D·ªÆ LI·ªÜU V√Ä M√î T·∫¢")
    
    # Option ƒë·ªÉ ch·ªçn d·ªØ li·ªáu
    data_option = st.radio(
        "Ch·ªçn ngu·ªìn d·ªØ li·ªáu:",
        ["üìä S·ª≠ d·ª•ng d·ªØ li·ªáu m·∫´u (ƒë√£ load s·∫µn)", "üìÅ T·∫£i file CSV c·ªßa b·∫°n"]
    )
    
    if data_option == "üìÅ T·∫£i file CSV c·ªßa b·∫°n":
        uploaded_file = st.file_uploader("Ch·ªçn file CSV", type=['csv'])
        
        if uploaded_file is not None:
            try:
                df_display = pd.read_csv(uploaded_file)
                st.success(f"‚úÖ ƒê√£ t·∫£i file th√†nh c√¥ng! S·ªë d√≤ng: {len(df_display)}")
            except Exception as e:
                st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {e}")
                df_display = eda_df
        else:
            st.info("üí° Vui l√≤ng ch·ªçn file CSV ƒë·ªÉ ti·∫øp t·ª•c")
            df_display = eda_df
    else:
        df_display = eda_df
    
    # Hi·ªÉn th·ªã d·ªØ li·ªáu
    st.subheader("üîé Xem tr∆∞·ªõc d·ªØ li·ªáu")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("T·ªïng s·ªë b·ªánh nh√¢n", len(df_display))
    with col2:
        st.metric("S·ªë features", len(df_display.columns))
    with col3:
        if 'B·ªánh_Tim' in df_display.columns:
            benh_rate = df_display['B·ªánh_Tim'].mean() * 100
            st.metric("T·ª∑ l·ªá b·ªánh", f"{benh_rate:.1f}%")
    
    # Hi·ªÉn th·ªã m·∫´u d·ªØ li·ªáu
    st.dataframe(df_display.head(20), use_container_width=True, height=400)
    
    # Th·ªëng k√™ m√¥ t·∫£
    st.subheader("üìà Th·ªëng k√™ m√¥ t·∫£")
    st.dataframe(df_display.describe(), use_container_width=True)
    
    st.markdown("---")
    
    # M√¥ t·∫£ c√°c c·ªôt
    st.subheader("üìò √ù nghƒ©a c√°c c·ªôt d·ªØ li·ªáu")

    data_desc = pd.DataFrame([
        ["Tu·ªïi", "Tu·ªïi b·ªánh nh√¢n", "28-77 tu·ªïi", "Nguy c∆° tƒÉng theo tu·ªïi"],
        ["Gi·ªõi_t√≠nh", "Gi·ªõi t√≠nh (0=N·ªØ, 1=Nam)", "Binary", "Nam c√≥ nguy c∆° cao h∆°n (63.2%)"],
        ["Lo·∫°i_ƒêau_Ng·ª±c", "Ph√¢n lo·∫°i ƒëau ng·ª±c", "ATA/NAP/ASY/TA", "ASY (kh√¥ng tri·ªáu ch·ª©ng) nguy hi·ªÉm nh·∫•t (79%)"],
        ["Huy·∫øt_√Åp_Ngh·ªâ", "Huy·∫øt √°p t√¢m thu l√∫c ngh·ªâ", "mmHg", "Cao huy·∫øt √°p ‚Üí tƒÉng nguy c∆°"],
        ["Cholesterol", "Cholesterol to√†n ph·∫ßn", "mg/dL", "X∆° v·ªØa ƒë·ªông m·∫°ch n·∫øu cao"],
        ["ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i", "ƒê∆∞·ªùng huy·∫øt l√∫c ƒë√≥i (>120mg/dL)", "0/1", "Li√™n quan ti·ªÉu ƒë∆∞·ªùng (79.4% n·∫øu cao)"],
        ["ƒêi·ªán_T√¢m_ƒê·ªì", "K·∫øt qu·∫£ ECG l√∫c ngh·ªâ", "Normal/ST/LVH", "B·∫•t th∆∞·ªùng ECG ‚Üí nguy c∆°"],
        ["Nh·ªãp_Tim_T·ªëi_ƒêa", "Nh·ªãp tim khi g·∫Øng s·ª©c", "nh·ªãp/ph√∫t", "Th·∫•p ‚Üí kh·∫£ nƒÉng tim k√©m"],
        ["ƒêau_Th·∫Øt_V·∫≠n_ƒê·ªông", "ƒêau ng·ª±c khi v·∫≠n ƒë·ªông", "0=Kh√¥ng, 1=C√≥", "C√≥ ƒëau ‚Üí 85.2% nguy c∆° b·ªánh"],
        ["ƒê·ªô_Ch√™nh_ST", "ST depression (Oldpeak)", "Gi√° tr·ªã th·ª±c", "√Çm = ST Elevation (nh·ªìi m√°u c·∫•p)"],
        ["ƒê·ªô_D·ªëc_ST", "H√¨nh d·∫°ng ƒëo·∫°n ST", "Up/Flat/Down", "Flat/Down ‚Üí 78-83% nguy c∆°"],
        ["Cholesterol_Tuoi", "Cholesterol chia cho tu·ªïi", "T√≠nh to√°n", "Feature engineering - ƒë√°nh gi√° theo tu·ªïi"],
        ["NguyCo_TimMach_RatCao", "K·∫øt h·ª£p nhi·ªÅu y·∫øu t·ªë nguy c∆°", "0/1", "Feature engineering - c·∫£nh b√°o t·ªïng h·ª£p"],
        ["B·ªánh_Tim", "Ch·∫©n ƒëo√°n b·ªánh tim", "0=Kh·ªèe, 1=B·ªánh", "Bi·∫øn m·ª•c ti√™u (target)"]
    ], columns=["T√™n c·ªôt", "M√¥ t·∫£", "Gi√° tr·ªã", "√ù nghƒ©a y khoa"])

    st.dataframe(data_desc, use_container_width=True, height=500)
    
    # Download d·ªØ li·ªáu m·∫´u
    st.markdown("---")
    st.subheader("üíæ T·∫£i d·ªØ li·ªáu m·∫´u")
    
    csv = df_display.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• Download CSV",
        data=csv,
        file_name="heart_disease_sample.csv",
        mime="text/csv"
    )

# ============================================================
# 5. PH√ÇN T√çCH EDA
# ============================================================

elif page == "üìä Ph√¢n t√≠ch EDA":
    st.header("üìä PH√ÇN T√çCH D·ªÆ LI·ªÜU KH√ÅM PH√Å (EDA)")
    
    st.info("üí° C√°c bi·ªÉu ƒë·ªì d∆∞·ªõi ƒë√¢y ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông t·ª´ file eda.py trong qu√° tr√¨nh training")
    
    # Ph√¢n b·ªë bi·∫øn m·ª•c ti√™u
    st.subheader("üéØ Ph√¢n b·ªë bi·∫øn m·ª•c ti√™u (B·ªánh Tim)")
    
    fig_path = os.path.join(FIGURES_DIR, "1_Target.png")
    if os.path.exists(fig_path):
        img = Image.open(fig_path)
        st.image(img, use_column_width=True)
    else:
        # V·∫Ω l·∫°i n·∫øu kh√¥ng c√≥ file
        fig, ax = plt.subplots(figsize=(10, 5))
        eda_df['B·ªánh_Tim'].value_counts().plot(kind='bar', ax=ax, color=['#2ecc71', '#e74c3c'])
        ax.set_title("Ph√¢n b·ªë B·ªánh Tim", fontsize=16)
        ax.set_xlabel("T√¨nh tr·∫°ng (0=Kh·ªèe, 1=B·ªánh)")
        ax.set_ylabel("S·ªë l∆∞·ª£ng")
        st.pyplot(fig)
    
    st.markdown("---")
    
    # Ch·ªçn bi·∫øn ƒë·ªÉ ph√¢n t√≠ch
    st.subheader("üìà Ph√¢n t√≠ch theo bi·∫øn")
    
    analysis_type = st.selectbox(
        "Ch·ªçn lo·∫°i ph√¢n t√≠ch:",
        ["Bi·∫øn s·ªë (Numerical)", "Bi·∫øn ph√¢n lo·∫°i (Categorical)", "Ma tr·∫≠n t∆∞∆°ng quan"]
    )
    
    if analysis_type == "Bi·∫øn s·ªë (Numerical)":
        num_vars = ['Tu·ªïi', 'Huy·∫øt_√Åp_Ngh·ªâ', 'Cholesterol', 'Nh·ªãp_Tim_T·ªëi_ƒêa', 'ƒê·ªô_Ch√™nh_ST', 'Cholesterol_Tuoi']
        selected_var = st.selectbox("Ch·ªçn bi·∫øn s·ªë:", num_vars)
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Histogram + KDE
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.histplot(data=eda_df, x=selected_var, kde=True, hue='B·ªánh_Tim', ax=ax, palette=['#2ecc71', '#e74c3c'])
            ax.set_title(f"Ph√¢n b·ªë {selected_var}", fontsize=14)
            st.pyplot(fig)
        
        with col2:
            # Boxplot
            fig, ax = plt.subplots(figsize=(10, 6))
            sns.boxplot(data=eda_df, x='B·ªánh_Tim', y=selected_var, ax=ax, palette=['#2ecc71', '#e74c3c'])
            ax.set_title(f"{selected_var} theo t√¨nh tr·∫°ng b·ªánh", fontsize=14)
            ax.set_xticklabels(['Kh·ªèe', 'B·ªánh'])
            st.pyplot(fig)
        
        # Th·ªëng k√™ so s√°nh
        st.subheader(f"üìä Th·ªëng k√™ {selected_var}")
        stats_comparison = eda_df.groupby('B·ªánh_Tim')[selected_var].agg(['mean', 'median', 'std', 'min', 'max']).round(2)
        stats_comparison.index = ['Kh·ªèe (0)', 'B·ªánh (1)']
        st.dataframe(stats_comparison, use_container_width=True)
    
    elif analysis_type == "Bi·∫øn ph√¢n lo·∫°i (Categorical)":
        cat_vars = ['Gi·ªõi_t√≠nh', 'Lo·∫°i_ƒêau_Ng·ª±c', 'ƒêi·ªán_T√¢m_ƒê·ªì', 'ƒêau_Th·∫Øt_V·∫≠n_ƒê·ªông', 'ƒê·ªô_D·ªëc_ST', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i']
        selected_var = st.selectbox("Ch·ªçn bi·∫øn ph√¢n lo·∫°i:", cat_vars)
        
        # Crosstab
        st.subheader(f"üìä Ph√¢n t√≠ch {selected_var}")
        
        crosstab = pd.crosstab(eda_df[selected_var], eda_df['B·ªánh_Tim'], normalize='index') * 100
        crosstab.columns = ['Kh·ªèe (%)', 'B·ªánh (%)']
        st.dataframe(crosstab.round(2), use_container_width=True)
        
        # Countplot
        fig, ax = plt.subplots(figsize=(12, 6))
        sns.countplot(data=eda_df, x=selected_var, hue='B·ªánh_Tim', ax=ax, palette=['#2ecc71', '#e74c3c'])
        ax.set_title(f"Ph√¢n b·ªë {selected_var} theo t√¨nh tr·∫°ng b·ªánh", fontsize=14)
        ax.legend(title='B·ªánh Tim', labels=['Kh·ªèe', 'B·ªánh'])
        st.pyplot(fig)
        
        # Ph√°t hi·ªán nh√≥m nguy c∆° cao
        risk_rates = crosstab['B·ªánh (%)']
        high_risk = risk_rates[risk_rates > 60].sort_values(ascending=False)
        
        if len(high_risk) > 0:
            st.warning(f"‚ö†Ô∏è **NH√ìM NGUY C∆† CAO (>60%):**")
            for idx, val in high_risk.items():
                st.write(f"- **{selected_var} = {idx}:** {val:.1f}% nguy c∆° b·ªánh")
    
    else:  # Ma tr·∫≠n t∆∞∆°ng quan
        st.subheader("üîó Ma tr·∫≠n t∆∞∆°ng quan")
        
        # Ch·ªçn c·ªôt s·ªë
        numeric_cols = eda_df.select_dtypes(include=[np.number]).columns.tolist()
        
        if len(numeric_cols) > 0:
            corr_matrix = eda_df[numeric_cols].corr()
            
            fig, ax = plt.subplots(figsize=(14, 10))
            sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, 
                       square=True, linewidths=1, cbar_kws={"shrink": 0.8}, ax=ax)
            ax.set_title("Ma tr·∫≠n t∆∞∆°ng quan gi·ªØa c√°c bi·∫øn s·ªë", fontsize=16)
            st.pyplot(fig)
            
            # Top correlations with target
            if 'B·ªánh_Tim' in numeric_cols:
                st.subheader("üéØ T∆∞∆°ng quan v·ªõi bi·∫øn m·ª•c ti√™u (B·ªánh_Tim)")
                target_corr = corr_matrix['B·ªánh_Tim'].drop('B·ªánh_Tim').sort_values(ascending=False)
                
                fig, ax = plt.subplots(figsize=(10, 6))
                target_corr.plot(kind='barh', ax=ax, color=['#e74c3c' if x > 0 else '#3498db' for x in target_corr])
                ax.set_title("T∆∞∆°ng quan v·ªõi B·ªánh_Tim", fontsize=14)
                ax.set_xlabel("H·ªá s·ªë t∆∞∆°ng quan")
                st.pyplot(fig)
                
                st.dataframe(target_corr.to_frame('Correlation'), use_container_width=True)

# ============================================================
# 6. SO S√ÅNH M√î H√åNH
# ============================================================


elif page == "üî¨ So s√°nh m√¥ h√¨nh":
    st.header("üî¨ SO S√ÅNH 3 M√î H√åNH MACHINE LEARNING")
    
    st.info("üí° K·∫øt qu·∫£ ƒë∆∞·ª£c l·∫•y t·ª´ evaluation.py ƒë√£ ch·∫°y tr∆∞·ªõc ƒë√≥")
    
    # B·∫£ng so s√°nh metrics
    st.subheader("üìä B·∫£ng so s√°nh hi·ªáu su·∫•t")
    
    comparison_df = pd.DataFrame({
        'M√¥ h√¨nh': ['Random Forest', 'XGBoost üèÜ', 'Neural Network'],
        'Accuracy': [0.8804, 0.8207, 0.8696],
        'Precision': [0.8509, 0.7717, 0.8421],
        'Recall': [0.9510, 0.9608, 0.9412],
        'F1-Score': [0.8981, 0.8559, 0.8889],
        'AUC-ROC': [0.9232, 0.9064, 0.9449],
        'FN (B·ªè s√≥t)': [5, 4, 6],
        'Ng∆∞·ª°ng t·ªëi ∆∞u': [0.5491, 0.6711, 0.6184]
    })
    
    # Highlight best values
    st.dataframe(
        comparison_df.style.highlight_max(subset=['Recall', 'AUC-ROC'], color='lightgreen')
                          .highlight_min(subset=['FN (B·ªè s√≥t)'], color='lightgreen'),
        use_container_width=True
    )
    
    st.markdown("---")
    
    # Visualize comparison
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìà So s√°nh Metrics ch√≠nh")
        
        metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
        fig, ax = plt.subplots(figsize=(10, 6))
        
        x = np.arange(len(comparison_df['M√¥ h√¨nh']))
        width = 0.2
        
        for i, metric in enumerate(metrics_to_plot):
            ax.bar(x + i*width, comparison_df[metric], width, label=metric)
        
        ax.set_xlabel('M√¥ h√¨nh')
        ax.set_ylabel('Gi√° tr·ªã')
        ax.set_title('So s√°nh Metrics')
        ax.set_xticks(x + width * 1.5)
        ax.set_xticklabels(comparison_df['M√¥ h√¨nh'])
        ax.legend()
        ax.grid(axis='y', alpha=0.3)
        st.pyplot(fig)
    
    with col2:
        st.subheader("üéØ False Negatives (B·ªè s√≥t)")
        
        fig, ax = plt.subplots(figsize=(10, 6))
        colors = ['#3498db', '#2ecc71', '#e74c3c']
        bars = ax.barh(comparison_df['M√¥ h√¨nh'], comparison_df['FN (B·ªè s√≥t)'], color=colors)
        ax.set_xlabel('S·ªë b·ªánh nh√¢n b·ªã b·ªè s√≥t')
        ax.set_title('False Negatives - C√†ng th·∫•p c√†ng t·ªët')
        
        # Add value labels
        for bar in bars:
            width = bar.get_width()
            ax.text(width, bar.get_y() + bar.get_height()/2, 
                   f'{int(width)}', ha='left', va='center', fontweight='bold')
        
        ax.grid(axis='x', alpha=0.3)
        st.pyplot(fig)
    
    st.markdown("---")
    
    # So s√°nh Hidden Patterns
    st.subheader("üîç So s√°nh kh·∫£ nƒÉng ph√°t hi·ªán Hidden Patterns")
    
    patterns_df = pd.DataFrame({
        'Model': ['Random Forest', 'XGBoost', 'Neural Network'],
        'Nh√≥m_xuat_hien': [4, 5, 4],
        'Benh_nhan_phat_hien': [97, 102, 99],
        'Combo_patterns': ['0/5 (0%)', '3/5 (60%)', '4/5 (80%)']
    })
    
    st.dataframe(patterns_df, use_container_width=True)
    
    st.markdown("""
    **Gi·∫£i th√≠ch:**
    - **Nh√≥m_xuat_hien:** S·ªë nh√≥m x√°c su·∫•t c√≥ b·ªánh nh√¢n (c√†ng nhi·ªÅu c√†ng ƒëa d·∫°ng)
    - **Benh_nhan_phat_hien:** T·ªïng b·ªánh nh√¢n ph√°t hi·ªán v·ªõi x√°c su·∫•t ‚â• 25%
    - **Combo_patterns:** T·ª∑ l·ªá patterns k·∫øt h·ª£p nhi·ªÅu tri·ªáu ch·ª©ng
    
    ‚≠ê **XGBoost th·∫Øng v√¨:**
    - Ph√°t hi·ªán 5 nh√≥m nguy c∆° (ƒëa d·∫°ng nh·∫•t)
    - Ph√°t hi·ªán 102 b·ªánh nh√¢n (nh·∫°y nh·∫•t)
    - Recall cao nh·∫•t (96.08%)
    - B·ªè s√≥t √≠t nh·∫•t (4 FN)
    """)
    
    st.markdown("---")
    
    # Hi·ªÉn th·ªã ROC Curves
    st.subheader("üìâ ƒê∆∞·ªùng cong ROC")
    
    roc_img_path = os.path.join(FIGURES_DIR, "Comparison_ROC.png")
    if os.path.exists(roc_img_path):
        img = Image.open(roc_img_path)
        st.image(img, use_column_width=True)
    else:
        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ bi·ªÉu ƒë·ªì ROC. H√£y ch·∫°y evaluation.py tr∆∞·ªõc!")
    
    # Confusion Matrices
    st.subheader("üìä Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)")
    
    cm_img_path = os.path.join(FIGURES_DIR, "Comparison_ConfusionMatrix.png")
    if os.path.exists(cm_img_path):
        img = Image.open(cm_img_path)
        st.image(img, use_column_width=True)
    else:
        st.warning("‚ö†Ô∏è Ch∆∞a c√≥ Confusion Matrix. H√£y ch·∫°y evaluation.py tr∆∞·ªõc!")
    
    st.markdown("---")
    
    # Khuy·∫øn ngh·ªã
    st.subheader("üí° Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng")
    
    rec_col1, rec_col2, rec_col3 = st.columns(3)
    
    with rec_col1:
        st.markdown("""
        <div style='background-color:#d4edda; padding:15px; border-radius:10px; border-left:5px solid #28a745;'>
            <h4>üè• ·ª®ng d·ª•ng y t·∫ø</h4>
            <p><strong>‚Üí XGBoost</strong></p>
            <ul>
                <li>Recall cao nh·∫•t (96.08%)</li>
                <li>B·ªè s√≥t √≠t nh·∫•t (4 FN)</li>
                <li>An to√†n cho screening</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with rec_col2:
        st.markdown("""
        <div style='background-color:#d1ecf1; padding:15px; border-radius:10px; border-left:5px solid #0c5460;'>
            <h4>üéØ C·∫ßn ch√≠nh x√°c cao</h4>
            <p><strong>‚Üí Random Forest</strong></p>
            <ul>
                <li>Accuracy cao nh·∫•t (88.04%)</li>
                <li>F1-Score cao nh·∫•t (0.8981)</li>
                <li>C√¢n b·∫±ng t·ªët</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with rec_col3:
        st.markdown("""
        <div style='background-color:#fff3cd; padding:15px; border-radius:10px; border-left:5px solid #856404;'>
            <h4>üî¨ Nghi√™n c·ª©u khoa h·ªçc</h4>
            <p><strong>‚Üí C·∫£ 3 m√¥ h√¨nh</strong></p>
            <ul>
                <li>So s√°nh ensemble</li>
                <li>Ph√°t hi·ªán ƒëa d·∫°ng</li>
                <li>AUC-ROC cao nh·∫•t: NN</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

# ============================================================
# 7. D·ª∞ ƒêO√ÅN NGUY C∆†
# ============================================================

elif page == "ü©∫ D·ª± ƒëo√°n nguy c∆°":
    st.header("ü©∫ D·ª∞ ƒêO√ÅN NGUY C∆† B·ªÜNH TIM")
    
    st.markdown("""
    <div class="warning-box">
        <strong>‚ö†Ô∏è CH√ö √ù QUAN TR·ªåNG:</strong> K·∫øt qu·∫£ d·ª± ƒëo√°n ch·ªâ mang t√≠nh tham kh·∫£o. 
        Vui l√≤ng tham kh·∫£o √Ω ki·∫øn b√°c sƒ© chuy√™n khoa ƒë·ªÉ c√≥ ch·∫©n ƒëo√°n ch√≠nh x√°c!
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Form nh·∫≠p li·ªáu
    st.subheader("üìù Nh·∫≠p th√¥ng tin b·ªánh nh√¢n")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**Th√¥ng tin c∆° b·∫£n:**")
        age = st.number_input("Tu·ªïi", min_value=20, max_value=100, value=50, step=1)
        sex = st.selectbox("Gi·ªõi t√≠nh", ["Nam", "N·ªØ"])
        chest_pain = st.selectbox("Lo·∫°i ƒëau ng·ª±c", ["ATA (Kh√¥ng ƒëi·ªÉn h√¨nh)", "NAP (Kh√¥ng ƒëau ng·ª±c)", "ASY (Kh√¥ng tri·ªáu ch·ª©ng)", "TA (ƒêi·ªÉn h√¨nh)"])
    
    with col2:
        st.markdown("**Ch·ªâ s·ªë sinh h·ªçc:**")
        bp = st.number_input("Huy·∫øt √°p ngh·ªâ (mmHg)", min_value=80, max_value=200, value=120, step=5)
        chol = st.number_input("Cholesterol (mg/dL)", min_value=100, max_value=600, value=200, step=10)
        fbs = st.selectbox("ƒê∆∞·ªùng huy·∫øt ƒë√≥i (>120 mg/dL)", ["Kh√¥ng (0)", "C√≥ (1)"])
    
    with col3:
        st.markdown("**ƒêi·ªán t√¢m ƒë·ªì & v·∫≠n ƒë·ªông:**")
        ecg = st.selectbox("K·∫øt qu·∫£ ECG", ["Normal", "ST", "LVH"])
        max_hr = st.number_input("Nh·ªãp tim t·ªëi ƒëa", min_value=60, max_value=220, value=150, step=5)
        angina = st.selectbox("ƒêau th·∫Øt v·∫≠n ƒë·ªông", ["Kh√¥ng (N)", "C√≥ (Y)"])
        oldpeak = st.number_input("ƒê·ªô ch√™nh ST (Oldpeak)", min_value=-3.0, max_value=7.0, value=0.0, step=0.1)
        st_slope = st.selectbox("ƒê·ªô d·ªëc ST", ["Up", "Flat", "Down"])
    
    st.markdown("---")
    
    # Ch·ªçn m√¥ h√¨nh
    model_choice = st.multiselect(
        "Ch·ªçn m√¥ h√¨nh d·ª± ƒëo√°n (c√≥ th·ªÉ ch·ªçn nhi·ªÅu):",
        ["Random Forest", "XGBoost", "Neural Network"],
        default=["XGBoost"]
    )
    
    if st.button("üîç D·ª∞ ƒêO√ÅN NGUY C∆†", type="primary"):
        if len(model_choice) == 0:
            st.error("‚ùå Vui l√≤ng ch·ªçn √≠t nh·∫•t 1 m√¥ h√¨nh!")
        else:
            with st.spinner("ƒêang x·ª≠ l√Ω d·ªØ li·ªáu v√† d·ª± ƒëo√°n..."):
                try:
                    # ===== B∆Ø·ªöC 2: Input dict (15 features, CH∆ØA engineered) =====
                    input_dict = {
                        'Tu·ªïi': age,
                        'Gi·ªõi_t√≠nh': 1 if sex == "Nam" else 0,
                        'Huy·∫øt_√Åp_Ngh·ªâ': bp,
                        'Cholesterol': chol,
                        'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i': 1 if fbs == "C√≥ (1)" else 0,
                        'Nh·ªãp_Tim_T·ªëi_ƒêa': max_hr,
                        'ƒêau_Th·∫Øt_V·∫≠n_ƒê·ªông': 1 if angina == "C√≥ (Y)" else 0,
                        'ƒê·ªô_Ch√™nh_ST': oldpeak,
                    }
                    
                    # ===== B∆Ø·ªöC 3: IMPUTATION - Numpy array thu·∫ßn t√∫y =====
                    impute_values = np.array([[
                        input_dict['Cholesterol'],
                        input_dict['Huy·∫øt_√Åp_Ngh·ªâ'],
                        input_dict['Tu·ªïi'],
                        input_dict['Nh·ªãp_Tim_T·ªëi_ƒêa']
                    ]])
                    
                    imputed_values = imputer.transform(impute_values)
                    
                    # G√°n l·∫°i v√†o dict
                    input_dict['Cholesterol'] = float(imputed_values[0, 0])
                    input_dict['Huy·∫øt_√Åp_Ngh·ªâ'] = float(imputed_values[0, 1])
                    input_dict['Tu·ªïi'] = float(imputed_values[0, 2])
                    input_dict['Nh·ªãp_Tim_T·ªëi_ƒêa'] = float(imputed_values[0, 3])
                    
                    # ===== B∆Ø·ªöC 4: FEATURE ENGINEERING (SAU imputation) =====
                    input_dict['Cholesterol_Tuoi'] = input_dict['Cholesterol'] / input_dict['Tu·ªïi']
                    input_dict['NguyCo_TimMach_RatCao'] = int(
                        (input_dict['Huy·∫øt_√Åp_Ngh·ªâ'] >= 140) and (input_dict['Cholesterol'] >= 240)
                    )
                    
                    # ===== B∆Ø·ªöC 5: Encoding categorical =====
                    chest_pain_map = {"ATA (Kh√¥ng ƒëi·ªÉn h√¨nh)": "ATA", "NAP (Kh√¥ng ƒëau ng·ª±c)": "NAP", 
                                    "ASY (Kh√¥ng tri·ªáu ch·ª©ng)": "ASY", "TA (ƒêi·ªÉn h√¨nh)": "TA"}
                    cp_code = chest_pain_map[chest_pain]
                    
                    input_dict['Lo·∫°i_ƒêau_Ng·ª±c_ATA'] = 1 if cp_code == 'ATA' else 0
                    input_dict['Lo·∫°i_ƒêau_Ng·ª±c_NAP'] = 1 if cp_code == 'NAP' else 0
                    input_dict['Lo·∫°i_ƒêau_Ng·ª±c_TA'] = 1 if cp_code == 'TA' else 0
                    
                    input_dict['ƒêi·ªán_T√¢m_ƒê·ªì_Normal'] = 1 if ecg == 'Normal' else 0
                    input_dict['ƒêi·ªán_T√¢m_ƒê·ªì_ST'] = 1 if ecg == 'ST' else 0
                    
                    input_dict['ƒê·ªô_D·ªëc_ST_Flat'] = 1 if st_slope == 'Flat' else 0
                    input_dict['ƒê·ªô_D·ªëc_ST_Up'] = 1 if st_slope == 'Up' else 0
                    
                    # ===== B∆Ø·ªöC 6: Create DataFrame (1 l·∫ßn duy nh·∫•t v·ªõi 17 features) =====
                    input_data = pd.DataFrame([input_dict])
                    
                    # ===== B∆Ø·ªöC 7: Align v·ªõi feature_cols =====
                    X = input_data[feature_cols].copy()
                    
                    # ===== B∆Ø·ªöC 8: SCALING =====
                    cols_scale = ['Tu·ªïi', 'Huy·∫øt_√Åp_Ngh·ªâ', 'Cholesterol', 'Nh·ªãp_Tim_T·ªëi_ƒêa', 
                                 'ƒê·ªô_Ch√™nh_ST', 'Cholesterol_Tuoi']
                    X[cols_scale] = scaler.transform(X[cols_scale].values)
                    
                    # D·ª± ƒëo√°n
                    st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω th√†nh c√¥ng!")
                    st.markdown("---")
                    
                    st.subheader("üìä K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN")
                    
                    results = []
                    
                    for model_name in model_choice:
                        if model_name == "Random Forest":
                            model = models['rf']
                            threshold = metadata['rf']['threshold']
                        elif model_name == "XGBoost":
                            model = models['xgb']
                            threshold = metadata['xgb']['threshold']
                        else:  # Neural Network
                            model = models['nn']
                            threshold = metadata['nn']['threshold']
                        
                        # Predict probability
                        prob = model.predict_proba(X)[0][1]
                        prediction = 1 if prob >= threshold else 0
                        
                        results.append({
                            'M√¥ h√¨nh': model_name,
                            'X√°c su·∫•t b·ªánh': f"{prob*100:.2f}%",
                            'D·ª± ƒëo√°n': 'C√≥ nguy c∆° b·ªánh tim ‚ö†Ô∏è' if prediction == 1 else 'Kh√¥ng c√≥ nguy c∆° ‚úÖ',
                            'Ng∆∞·ª°ng': f"{threshold:.4f}",
                            'Prob_value': prob
                        })
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    result_cols = st.columns(len(results))
                    
                    for i, result in enumerate(results):
                        with result_cols[i]:
                            prob_val = result['Prob_value']
                            color = '#e74c3c' if prob_val >= 0.5 else '#2ecc71'
                            
                            st.markdown(f"""
                            <div style='background-color:{color}15; padding:20px; border-radius:10px; border-left:5px solid {color};'>
                                <h3 style='color:{color};'>{result['M√¥ h√¨nh']}</h3>
                                <h1 style='color:{color}; margin:10px 0;'>{result['X√°c su·∫•t b·ªánh']}</h1>
                                <p style='font-size:16px; margin:5px 0;'><strong>{result['D·ª± ƒëo√°n']}</strong></p>
                                <p style='font-size:12px; color:#666;'>Ng∆∞·ª°ng: {result['Ng∆∞·ª°ng']}</p>
                            </div>
                            """, unsafe_allow_html=True)
                            
                            # Progress bar
                            st.progress(float(prob_val))
                    
                    st.markdown("---")
                    
                    # B·∫£ng t·ªïng h·ª£p
                    st.subheader("üìã T·ªïng h·ª£p k·∫øt qu·∫£")
                    results_df = pd.DataFrame(results)[['M√¥ h√¨nh', 'X√°c su·∫•t b·ªánh', 'D·ª± ƒëo√°n', 'Ng∆∞·ª°ng']]
                    st.dataframe(results_df, use_container_width=True)
                    
                    # Gi·∫£i th√≠ch
                    st.markdown("---")
                    st.subheader("üí° Gi·∫£i th√≠ch k·∫øt qu·∫£")
                    
                    avg_prob = np.mean([r['Prob_value'] for r in results])
                    
                    if avg_prob >= 0.7:
                        st.error("""
                        **üö® NGUY C∆† CAO:** X√°c su·∫•t trung b√¨nh ‚â• 70%
                        
                        **Khuy·∫øn ngh·ªã:**
                        - ‚ö†Ô∏è C·∫ßn kh√°m tim m·∫°ch NGAY
                        - L√†m c√°c x√©t nghi·ªám chuy√™n s√¢u (ECG, Holter, si√™u √¢m tim)
                        - Tham kh·∫£o b√°c sƒ© tim m·∫°ch
                        """)
                    elif avg_prob >= 0.5:
                        st.warning("""
                        **‚ö†Ô∏è NGUY C∆† TRUNG B√åNH:** X√°c su·∫•t 50-70%
                        
                        **Khuy·∫øn ngh·ªã:**
                        - N√™n ƒëi kh√°m ƒë·ªÉ ki·ªÉm tra
                        - Theo d√µi c√°c tri·ªáu ch·ª©ng
                        - ƒêi·ªÅu ch·ªânh l·ªëi s·ªëng (ƒÉn u·ªëng, t·∫≠p luy·ªán)
                        """)
                    else:
                        st.success("""
                        **‚úÖ NGUY C∆† TH·∫§P:** X√°c su·∫•t < 50%
                        
                        **Khuy·∫øn ngh·ªã:**
                        - Duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh
                        - Kh√°m ƒë·ªãnh k·ª≥ h√†ng nƒÉm
                        - Ki·ªÉm so√°t cholesterol, huy·∫øt √°p
                        """)
                    
                    # Th√¥ng tin ƒë·∫ßu v√†o
                    with st.expander("üìã Xem th√¥ng tin ƒë·∫ßu v√†o ƒë√£ x·ª≠ l√Ω"):
                        st.write("**D·ªØ li·ªáu g·ªëc:**")
                        st.json(input_data)
                        st.write("**Features sau preprocessing:**")
                        st.dataframe(X.head(), use_container_width=True)
                
                except Exception as e:
                    st.error(f"‚ùå L·ªói khi d·ª± ƒëo√°n: {e}")
                    st.exception(e)

# ============================================================
# 8. HIDDEN PATTERNS
# ============================================================

elif page == "üîç Hidden Patterns":
    st.header("üîç C√ÅC M·∫™U ·∫®N ƒê∆Ø·ª¢C PH√ÅT HI·ªÜN (HIDDEN PATTERNS)")
    
    st.info("""
    üí° **Hidden Patterns** l√† c√°c t·ªï h·ª£p tri·ªáu ch·ª©ng c·ª• th·ªÉ d·∫´n ƒë·∫øn c√°c m·ª©c ƒë·ªô nguy c∆° b·ªánh tim kh√°c nhau.
    C√°c m·∫´u n√†y ƒë∆∞·ª£c tr√≠ch xu·∫•t t·ª± ƒë·ªông t·ª´ 3 m√¥ h√¨nh ML trong qu√° tr√¨nh training.
    """)
    
    # Ch·ªçn m√¥ h√¨nh
    pattern_model = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh ƒë·ªÉ xem patterns:",
        ["Random Forest", "XGBoost (Khuy·∫øn ngh·ªã)", "Neural Network"]
    )
    
    st.markdown("---")
    
    if pattern_model == "Random Forest":
        st.subheader("üå≥ Hidden Patterns t·ª´ Random Forest")
        
        st.markdown("""
        **Ph∆∞∆°ng ph√°p:** Tr√≠ch xu·∫•t rules t·ª´ 50 c√¢y quy·∫øt ƒë·ªãnh
        **K·∫øt qu·∫£:** 5 patterns (4 nh√≥m nguy c∆°), 97 b·ªánh nh√¢n ph√°t hi·ªán
        """)
        
        patterns = [
            {
                'no': 1,
                'conditions': ['ƒê·ªô_D·ªëc_ST_Up ‚â§ 0.50', 'Gi·ªõi_t√≠nh > 0.50 (Nam)', 'ƒê·ªô_Ch√™nh_ST ‚â§ -0.30'],
                'risk': '100%',
                'patients': 51,
                'level': 'R·∫•t cao'
            },
            {
                'no': 2,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > -0.03', 'ƒê·ªô_Ch√™nh_ST > 1.23', 'Huy·∫øt_√Åp_Ngh·ªâ > -1.27'],
                'risk': '100%',
                'patients': 44,
                'level': 'R·∫•t cao'
            },
            {
                'no': 3,
                'conditions': ['ƒê·ªô_D·ªëc_ST_Flat > 0.50', 'Lo·∫°i_ƒêau_Ng·ª±c_NAP ‚â§ 0.50', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i > 0.50', 'ƒê·ªô_Ch√™nh_ST ‚â§ 0.93'],
                'risk': '100%',
                'patients': 44,
                'level': 'R·∫•t cao'
            },
            {
                'no': 4,
                'conditions': ['Lo·∫°i_ƒêau_Ng·ª±c_NAP > 0.50', 'ƒêau_Th·∫Øt_V·∫≠n_ƒê·ªông > 0.50', 'Nh·ªãp_Tim_T·ªëi_ƒêa ‚â§ 0.36', 'Huy·∫øt_√Åp_Ngh·ªâ ‚â§ -0.88'],
                'risk': '33%',
                'patients': 3,
                'level': 'Trung b√¨nh'
            },
            {
                'no': 5,
                'conditions': ['ƒêau_Th·∫Øt_V·∫≠n_ƒê·ªông > 0.50', 'Lo·∫°i_ƒêau_Ng·ª±c_TA > 0.50'],
                'risk': '40%',
                'patients': 3,
                'level': 'Trung b√¨nh'
            }
        ]
        
        for p in patterns:
            risk_color = '#e74c3c' if p['level'] == 'R·∫•t cao' else ('#ff9800' if p['level'] == 'Trung b√¨nh' else '#2ecc71')
            
            st.markdown(f"""
            <div style='background-color:{risk_color}15; padding:15px; margin:10px 0; border-radius:10px; border-left:5px solid {risk_color};'>
                <h4 style='color:{risk_color};'>Pattern #{p['no']} - Nguy c∆° {p['risk']} ({p['level']})</h4>
                <p><strong>N·∫æU:</strong></p>
                <ul>
                    {''.join([f'<li>{cond}</li>' for cond in p['conditions']])}
                </ul>
                <p><strong>‚Üí CƒÉn c·ª©:</strong> {p['patients']} b·ªánh nh√¢n trong t·∫≠p hu·∫•n luy·ªán</p>
            </div>
            """, unsafe_allow_html=True)
    
    elif pattern_model == "XGBoost (Khuy·∫øn ngh·ªã)":
        st.subheader("üöÄ Hidden Patterns t·ª´ XGBoost")
        
        st.markdown("""
        **Ph∆∞∆°ng ph√°p:** Ph√¢n t√≠ch theo probability ranges (6 ranges)
        **K·∫øt qu·∫£:** 5 patterns (5 nh√≥m nguy c∆°), **102 b·ªánh nh√¢n ph√°t hi·ªán** ‚≠ê
        **ƒê·∫∑c bi·ªát:** 3/5 patterns l√† combo (k·∫øt h·ª£p 2 tri·ªáu ch·ª©ng)
        """)
        
        patterns = [
            {
                'no': 1,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.67', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i > 0.00'],
                'risk': '92%',
                'patients': 57,
                'level': 'R·∫•t cao',
                'is_combo': True
            },
            {
                'no': 2,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.75'],
                'risk': '92%',
                'patients': 57,
                'level': 'R·∫•t cao',
                'is_combo': False
            },
            {
                'no': 3,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.67', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i > 0.00'],
                'risk': '77%',
                'patients': 36,
                'level': 'Cao',
                'is_combo': True
            },
            {
                'no': 4,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.53', 'ƒêau_Th·∫Øt_V·∫≠n_ƒê·ªông > 0.00'],
                'risk': '62%',
                'patients': 4,
                'level': 'Trung b√¨nh',
                'is_combo': True
            },
            {
                'no': 5,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > -0.60'],
                'risk': '48%',
                'patients': 2,
                'level': 'V·ª´a ph·∫£i',
                'is_combo': False
            }
        ]
        
        for p in patterns:
            risk_color = '#e74c3c' if p['level'] == 'R·∫•t cao' else ('#ff5722' if p['level'] == 'Cao' else ('#ff9800' if p['level'] == 'Trung b√¨nh' else '#ffc107'))
            combo_badge = 'üîó COMBO' if p['is_combo'] else 'üìå SINGLE'
            
            st.markdown(f"""
            <div style='background-color:{risk_color}15; padding:15px; margin:10px 0; border-radius:10px; border-left:5px solid {risk_color};'>
                <h4 style='color:{risk_color};'>Pattern #{p['no']} - Nguy c∆° {p['risk']} ({p['level']}) {combo_badge}</h4>
                <p><strong>N·∫æU:</strong></p>
                <ul>
                    {''.join([f'<li>{cond}</li>' for cond in p['conditions']])}
                </ul>
                <p><strong>‚Üí CƒÉn c·ª©:</strong> XGBoost ph√¢n t√≠ch t·ª´ {p['patients']} b·ªánh nh√¢n</p>
                {'<p style="font-size:12px; color:#666;"><em>Ghi ch√∫: M·ª©c ƒë·ªô tri·ªáu ch·ª©ng KH√ÅC NHAU gi·ªØa c√°c nh√≥m</em></p>' if p['is_combo'] else ''}
            </div>
            """, unsafe_allow_html=True)
        
        st.success("""
        ‚≠ê **T·∫†I SAO XGBOOST T·ªêT NH·∫§T?**
        - Ph√°t hi·ªán 5 nh√≥m nguy c∆° (ƒëa d·∫°ng nh·∫•t)
        - Ph√°t hi·ªán 102 b·ªánh nh√¢n (nhi·ªÅu nh·∫•t)
        - 60% patterns l√† combo (ph√°t hi·ªán t∆∞∆°ng t√°c)
        - C√≥ threshold c·ª• th·ªÉ cho t·ª´ng m·ª©c ƒë·ªô tri·ªáu ch·ª©ng
        """)
    
    else:  # Neural Network
        st.subheader("üß† Hidden Patterns t·ª´ Neural Network")
        
        st.markdown("""
        **Ph∆∞∆°ng ph√°p:** Permutation Importance + Probability ranges (5 ranges)
        **K·∫øt qu·∫£:** 5 patterns (4 nh√≥m nguy c∆°), 99 b·ªánh nh√¢n ph√°t hi·ªán
        **ƒê·∫∑c bi·ªát:** 4/5 patterns l√† combo (80% - cao nh·∫•t!)
        """)
        
        patterns = [
            {
                'no': 1,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.67', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i > 0.00'],
                'risk': '92%',
                'patients': 72,
                'level': 'R·∫•t cao',
                'is_combo': True
            },
            {
                'no': 2,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.95'],
                'risk': '92%',
                'patients': 72,
                'level': 'R·∫•t cao',
                'is_combo': False
            },
            {
                'no': 3,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.33', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i > 0.00'],
                'risk': '77%',
                'patients': 14,
                'level': 'Cao',
                'is_combo': True
            },
            {
                'no': 4,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.37', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i > 0.00'],
                'risk': '62%',
                'patients': 10,
                'level': 'Trung b√¨nh',
                'is_combo': True
            },
            {
                'no': 5,
                'conditions': ['ƒê·ªô_Ch√™nh_ST > 0.33', 'ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i > 0.00'],
                'risk': '32%',
                'patients': 3,
                'level': 'Th·∫•p',
                'is_combo': True
            }
        ]
        
        for p in patterns:
            risk_color = '#e74c3c' if p['level'] == 'R·∫•t cao' else ('#ff5722' if p['level'] == 'Cao' else ('#ff9800' if p['level'] == 'Trung b√¨nh' else '#2ecc71'))
            combo_badge = 'üîó COMBO' if p['is_combo'] else 'üìå SINGLE'
            
            st.markdown(f"""
            <div style='background-color:{risk_color}15; padding:15px; margin:10px 0; border-radius:10px; border-left:5px solid {risk_color};'>
                <h4 style='color:{risk_color};'>Pattern #{p['no']} - Nguy c∆° {p['risk']} ({p['level']}) {combo_badge}</h4>
                <p><strong>N·∫æU:</strong></p>
                <ul>
                    {''.join([f'<li>{cond}</li>' for cond in p['conditions']])}
                </ul>
                <p><strong>‚Üí CƒÉn c·ª©:</strong> Neural Network ph√¢n t√≠ch t·ª´ {p['patients']} b·ªánh nh√¢n</p>
                {'<p style="font-size:12px; color:#666;"><em>Ghi ch√∫: M·ª©c ƒë·ªô tri·ªáu ch·ª©ng KH√ÅC NHAU gi·ªØa c√°c nh√≥m</em></p>' if p['is_combo'] else ''}
            </div>
            """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    # Gi·∫£i th√≠ch t·∫°i sao c√πng tri·ªáu ch·ª©ng kh√°c % nguy c∆°
    st.subheader("‚ùì T·∫°i sao c√πng tri·ªáu ch·ª©ng m√† kh√°c % nguy c∆°?")
    
    st.info("""
    **V√ç D·ª§:** ƒê·ªô_Ch√™nh_ST xu·∫•t hi·ªán ·ªü nhi·ªÅu patterns v·ªõi % kh√°c nhau:
    - Pattern 1: ƒê·ªô_Ch√™nh_ST > 0.67 ‚Üí 92% nguy c∆°
    - Pattern 3: ƒê·ªô_Ch√™nh_ST > 0.67 ‚Üí 77% nguy c∆°
    - Pattern 5: ƒê·ªô_Ch√™nh_ST > 0.33 ‚Üí 32% nguy c∆°
    
    **GI·∫¢I TH√çCH:**
    1. **M·ª®C ƒê·ªò tri·ªáu ch·ª©ng kh√°c nhau:** > 0.67 vs > 0.33 (cao h∆°n = nguy hi·ªÉm h∆°n)
    2. **T·ªî H·ª¢P v·ªõi tri·ªáu ch·ª©ng kh√°c:** C√πng v·ªõi ƒê∆∞·ªùng_Huy·∫øt_ƒê√≥i hay kh√¥ng
    3. **NH√ìM b·ªánh nh√¢n kh√°c nhau:** ƒê·ªô tu·ªïi, gi·ªõi t√≠nh, ti·ªÅn s·ª≠ kh√°c nhau
    
    ‚Üí ƒê√¢y ch√≠nh l√† ∆∞u ƒëi·ªÉm c·ªßa **Hidden Patterns**: Ph√°t hi·ªán ƒë∆∞·ª£c s·ª± ph·ª©c t·∫°p v√† t∆∞∆°ng t√°c gi·ªØa c√°c tri·ªáu ch·ª©ng!
    """)

# ============================================================
# 9. H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG
# ============================================================

elif page == "üìñ H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng":
    st.header("üìñ H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG DASHBOARD")
    
    st.markdown("""
    ## üéØ M·ª•c ƒë√≠ch Dashboard
    
    Dashboard n√†y ƒë∆∞·ª£c x√¢y d·ª±ng ƒë·ªÉ minh h·ªça m·ªôt h·ªá th·ªëng Machine Learning ho√†n ch·ªânh trong lƒ©nh v·ª±c y t·∫ø,
    t·ª´ x·ª≠ l√Ω d·ªØ li·ªáu, ph√¢n t√≠ch, training model cho ƒë·∫øn tri·ªÉn khai d·ª± ƒëo√°n.
    
    ---
    
    ## üìã C√°c trang ch·ª©c nƒÉng
    
    ### 1. üè† Trang ch·ªß
    - T·ªïng quan v·ªÅ d·ª± √°n
    - Th·ªëng k√™ c∆° b·∫£n (918 b·ªánh nh√¢n, 17 features, 55.3% t·ª∑ l·ªá b·ªánh)
    - Quy tr√¨nh x·ª≠ l√Ω (Pipeline)
    - T√≠nh nƒÉng ch√≠nh c·ªßa dashboard
    
    ### 2. üìÇ D·ªØ li·ªáu & M√¥ t·∫£
    **Ch·ª©c nƒÉng:**
    - ‚úÖ T·∫£i file CSV c·ªßa b·∫°n HO·∫∂C d√πng d·ªØ li·ªáu m·∫´u
    - ‚úÖ Xem tr∆∞·ªõc d·ªØ li·ªáu (20 d√≤ng ƒë·∫ßu)
    - ‚úÖ Th·ªëng k√™ m√¥ t·∫£ (mean, std, min, max, ...)
    - ‚úÖ Gi·∫£i th√≠ch √Ω nghƒ©a t·ª´ng c·ªôt v·ªõi context y khoa
    - ‚úÖ Download d·ªØ li·ªáu m·∫´u v·ªÅ m√°y
    
    **C√°ch s·ª≠ d·ª•ng:**
    1. Ch·ªçn "T·∫£i file CSV c·ªßa b·∫°n"
    2. Click "Browse files" v√† ch·ªçn file .csv
    3. Dashboard s·∫Ω t·ª± ƒë·ªông load v√† hi·ªÉn th·ªã
    
    ### 3. üìä Ph√¢n t√≠ch EDA
    **Ch·ª©c nƒÉng:**
    - Ph√¢n b·ªë bi·∫øn m·ª•c ti√™u (B·ªánh Tim)
    - Ph√¢n t√≠ch bi·∫øn s·ªë: Histogram + Boxplot
    - Ph√¢n t√≠ch bi·∫øn ph√¢n lo·∫°i: Countplot + Crosstab
    - Ma tr·∫≠n t∆∞∆°ng quan
    - Ph√°t hi·ªán nh√≥m nguy c∆° cao (>60%)
    
    **C√°ch s·ª≠ d·ª•ng:**
    1. Ch·ªçn lo·∫°i ph√¢n t√≠ch (Numerical/Categorical/Correlation)
    2. Ch·ªçn bi·∫øn c·∫ßn ph√¢n t√≠ch
    3. Xem bi·ªÉu ƒë·ªì v√† th·ªëng k√™
    
    ### 4. üî¨ So s√°nh m√¥ h√¨nh
    **Ch·ª©c nƒÉng:**
    - B·∫£ng so s√°nh 3 m√¥ h√¨nh (RF, XGBoost, NN)
    - 8 metrics: Accuracy, Precision, Recall, F1, AUC-ROC, FN, Threshold
    - Bi·ªÉu ƒë·ªì so s√°nh metrics
    - Bi·ªÉu ƒë·ªì False Negatives (b·ªè s√≥t)
    - So s√°nh Hidden Patterns
    - ROC Curves
    - Confusion Matrices
    - Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng theo t·ª´ng m·ª•c ƒë√≠ch
    
    ### 5. ü©∫ D·ª± ƒëo√°n nguy c∆°
    **Ch·ª©c nƒÉng:**
    - Nh·∫≠p th√¥ng tin b·ªánh nh√¢n (11 tr∆∞·ªùng)
    - Ch·ªçn 1 ho·∫∑c nhi·ªÅu m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n
    - Hi·ªÉn th·ªã x√°c su·∫•t b·ªánh tim (%)
    - D·ª± ƒëo√°n: C√≥/Kh√¥ng nguy c∆°
    - Khuy·∫øn ngh·ªã y khoa d·ª±a tr√™n k·∫øt qu·∫£
    
    **C√°ch s·ª≠ d·ª•ng:**
    1. ƒêi·ªÅn ƒë·∫ßy ƒë·ªß th√¥ng tin b·ªánh nh√¢n:
       - **C∆° b·∫£n:** Tu·ªïi, Gi·ªõi t√≠nh, Lo·∫°i ƒëau ng·ª±c
       - **Sinh h·ªçc:** Huy·∫øt √°p, Cholesterol, ƒê∆∞·ªùng huy·∫øt ƒë√≥i
       - **ECG & V·∫≠n ƒë·ªông:** K·∫øt qu·∫£ ECG, Nh·ªãp tim, ƒêau th·∫Øt, Oldpeak, ST Slope
    2. Ch·ªçn m√¥ h√¨nh (m·∫∑c ƒë·ªãnh: XGBoost)
    3. Click "D·ª∞ ƒêO√ÅN NGUY C∆†"
    4. Xem k·∫øt qu·∫£ v√† khuy·∫øn ngh·ªã
    
    **Gi·∫£i th√≠ch k·∫øt qu·∫£:**
    - üö® **Nguy c∆° cao (‚â•70%):** C·∫ßn kh√°m ngay
    - ‚ö†Ô∏è **Nguy c∆° trung b√¨nh (50-70%):** N√™n ƒëi kh√°m ki·ªÉm tra
    - ‚úÖ **Nguy c∆° th·∫•p (<50%):** Duy tr√¨ l·ªëi s·ªëng l√†nh m·∫°nh
    
    ### 6. üîç Hidden Patterns
    **Ch·ª©c nƒÉng:**
    - Xem 5 patterns t·ª´ m·ªói m√¥ h√¨nh
    - Gi·∫£i th√≠ch t·ª´ng pattern: ƒêi·ªÅu ki·ªán ‚Üí Nguy c∆° ‚Üí S·ªë b·ªánh nh√¢n
    - Ph√¢n bi·ªát Single vs Combo patterns
    - Gi·∫£i th√≠ch t·∫°i sao c√πng tri·ªáu ch·ª©ng kh√°c % nguy c∆°
    
    **C√°c lo·∫°i patterns:**
    - üìå **SINGLE:** 1 tri·ªáu ch·ª©ng
    - üîó **COMBO:** 2-3 tri·ªáu ch·ª©ng k·∫øt h·ª£p
    
    ---
    
    ## ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng
    
    ### üî¥ V·ªÅ m·∫∑t y khoa:
    1. **KH√îNG t·ª± ch·∫©n ƒëo√°n** d·ª±a tr√™n k·∫øt qu·∫£ dashboard
    2. **KH√îNG thay ƒë·ªïi thu·ªëc** ho·∫∑c li·ªáu tr√¨nh ƒëi·ªÅu tr·ªã
    3. **PH·∫¢I tham kh·∫£o b√°c sƒ©** ƒë·ªÉ c√≥ ch·∫©n ƒëo√°n ch√≠nh x√°c
    4. Dashboard ch·ªâ mang t√≠nh ch·∫•t **h·ªó tr·ª£** v√† **minh h·ªça khoa h·ªçc**
    
    ### üìä V·ªÅ m·∫∑t k·ªπ thu·∫≠t:
    1. M√¥ h√¨nh ƒë∆∞·ª£c train tr√™n 918 b·ªánh nh√¢n ‚Üí **Ch∆∞a ƒë·ªß l·ªõn** cho production
    2. Recall 96% nghƒ©a l√† v·∫´n **b·ªè s√≥t 4%** (4/102 b·ªánh nh√¢n)
    3. False Positive cao (19-29) ‚Üí Nhi·ªÅu ng∆∞·ªùi kh·ªèe b·ªã d·ª± ƒëo√°n nh·∫ßm
    4. C·∫ßn **external validation** tr√™n dataset kh√°c
    5. C·∫ßn **clinical trials** v√† **FDA approval** tr∆∞·ªõc khi tri·ªÉn khai th·ª±c t·∫ø
    
    ---
    
    ## üöÄ H∆∞·ªõng ph√°t tri·ªÉn
    
    ### C·∫£i thi·ªán m√¥ h√¨nh:
    - Ensemble 3 m√¥ h√¨nh (Voting)
    - Th√™m Deep Learning (CNN, RNN)
    - SHAP values cho explainability
    
    ### TƒÉng d·ªØ li·ªáu:
    - T√≠ch h·ª£p th√™m datasets (>10,000 BN)
    - Real-time data t·ª´ b·ªánh vi·ªán
    - Multi-center validation
    
    ### Tri·ªÉn khai th·ª±c t·∫ø:
    - API RESTful (FastAPI)
    - Mobile app (Flutter)
    - T√≠ch h·ª£p h·ªá th·ªëng b·ªánh vi·ªán (FHIR)
    - HIPAA compliance
    
    ---
    
    ## üìû Li√™n h·ªá & H·ªó tr·ª£
    
    **Nh√≥m ph√°t tri·ªÉn:**
    - Nh√≥m 7 - S26-65TTNT
    - Nguy·ªÖn L√™ Minh H·∫≠u
    - Nguy·ªÖn ƒê·ª©c Huy
    
    **ƒê·ªì √°n m√¥n:** Machine Learning
    
    **GitHub:** [Link repository]
    
    ---
    
    ## üìö T√†i li·ªáu tham kh·∫£o
    
    1. UCI Heart Disease Dataset
    2. Kaggle Heart Disease Dataset
    3. scikit-learn Documentation
    4. XGBoost Documentation
    5. Streamlit Documentation
    
    ---
    
    <div style='background-color:#d4edda; padding:20px; border-radius:10px; border-left:5px solid #28a745; margin-top:30px;'>
        <h3 style='color:#155724;'>‚úÖ Checklist s·ª≠ d·ª•ng Dashboard</h3>
        <ul style='color:#155724;'>
            <li>‚òëÔ∏è ƒê√£ ƒë·ªçc h∆∞·ªõng d·∫´n v√† hi·ªÉu r√µ m·ª•c ƒë√≠ch</li>
            <li>‚òëÔ∏è ƒê√£ ch·∫°y preprocessing.py ‚Üí models ‚Üí evaluation.py</li>
            <li>‚òëÔ∏è ƒê√£ c√≥ ƒë·ªß 10 file .pkl trong saved_models/</li>
            <li>‚òëÔ∏è ƒê√£ c√≥ c√°c bi·ªÉu ƒë·ªì trong outputs/figures/</li>
            <li>‚òëÔ∏è Hi·ªÉu r·∫±ng k·∫øt qu·∫£ ch·ªâ mang t√≠nh tham kh·∫£o</li>
            <li>‚òëÔ∏è Kh√¥ng t·ª± ch·∫©n ƒëo√°n d·ª±a tr√™n dashboard</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# ============================================================
# FOOTER
# ============================================================

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; padding: 20px;'>
    <p><strong>ü´Ä Dashboard D·ª± ƒêo√°n B·ªánh Tim</strong></p>
    <p>Nh√≥m 7 - S26-65TTNT | ƒê·ªì √°n m√¥n Machine Learning</p>
    <p style='font-size: 12px;'>‚ö†Ô∏è Ch·ªâ mang t√≠nh nghi√™n c·ª©u v√† minh h·ªça - Kh√¥ng thay th·∫ø ch·∫©n ƒëo√°n y khoa</p>
</div>
""", unsafe_allow_html=True)
